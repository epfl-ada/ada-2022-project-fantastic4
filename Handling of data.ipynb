{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'Data/'\n",
    "CHARACTER_DATASET = DATA_FOLDER + 'character.metadata.tsv'\n",
    "MOVIE_DATASET = DATA_FOLDER + 'Movie.metadata.tsv'\n",
    "SUMMARIES_DATASET = DATA_FOLDER + 'plot_summaries.txt'\n",
    "NLP_FOLDER = DATA_FOLDER + 'corenlp_plot_summaries/'\n",
    "DEFAULT_COMPRESSION = 'gzip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(path, column_names, header=None, low_memory=False):\n",
    "    return pd.read_table(path, header=header, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_character = ['Wikipedia_movie_ID', 'Freebase_movie_ID', 'Movie_release_date', 'Character_name', 'Actor_date_of_birth', 'Actor_gender', 'Actor_height_meters', 'Actor_ethnicity_Freebase_ID', 'Actor_name', 'Actor_age_at_movie_release', 'Freebase_character_actor_map_ID', 'Freebase_character_ID', 'Freebase_actor_ID']\n",
    "columns_movie = ['Wikipedia_movie_ID', 'Freebase_movie_ID', 'Movie_name','Movie_release_date','Movie_box_office_revenue', 'Movie_runtime','Movie_languages','Movie_countries','Movie_genres' ]\n",
    "\n",
    "characters = load_metadata(CHARACTER_DATASET,column_names=columns_character)\n",
    "movies = load_metadata(MOVIE_DATASET,column_names=columns_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SUMMARIES_DATASET,'r', encoding='utf-8') as file:\n",
    "    summaries = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First glimpse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81741\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Movie_box_office_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_languages</th>\n",
       "      <th>Movie_countries</th>\n",
       "      <th>Movie_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wikipedia_movie_ID Freebase_movie_ID  \\\n",
       "0              975900         /m/03vyhn   \n",
       "1             3196793         /m/08yl5d   \n",
       "\n",
       "                                          Movie_name Movie_release_date  \\\n",
       "0                                     Ghosts of Mars         2001-08-24   \n",
       "1  Getting Away with Murder: The JonBenét Ramsey ...         2000-02-16   \n",
       "\n",
       "   Movie_box_office_revenue  Movie_runtime  \\\n",
       "0                14010832.0           98.0   \n",
       "1                       NaN           95.0   \n",
       "\n",
       "                      Movie_languages  \\\n",
       "0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "1  {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "                             Movie_countries  \\\n",
       "0  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "1  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "\n",
       "                                        Movie_genres  \n",
       "0  {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  \n",
       "1  {\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(movies))\n",
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450669\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Character_name</th>\n",
       "      <th>Actor_date_of_birth</th>\n",
       "      <th>Actor_gender</th>\n",
       "      <th>Actor_height_meters</th>\n",
       "      <th>Actor_ethnicity_Freebase_ID</th>\n",
       "      <th>Actor_name</th>\n",
       "      <th>Actor_age_at_movie_release</th>\n",
       "      <th>Freebase_character_actor_map_ID</th>\n",
       "      <th>Freebase_character_ID</th>\n",
       "      <th>Freebase_actor_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.78</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wikipedia_movie_ID Freebase_movie_ID Movie_release_date  \\\n",
       "0              975900         /m/03vyhn         2001-08-24   \n",
       "1              975900         /m/03vyhn         2001-08-24   \n",
       "\n",
       "               Character_name Actor_date_of_birth Actor_gender  \\\n",
       "0                    Akooshay          1958-08-26            F   \n",
       "1  Lieutenant Melanie Ballard          1974-08-15            F   \n",
       "\n",
       "   Actor_height_meters Actor_ethnicity_Freebase_ID          Actor_name  \\\n",
       "0                 1.62                         NaN      Wanda De Jesus   \n",
       "1                 1.78                  /m/044038p  Natasha Henstridge   \n",
       "\n",
       "   Actor_age_at_movie_release Freebase_character_actor_map_ID  \\\n",
       "0                        42.0                      /m/0bgchxw   \n",
       "1                        27.0                       /m/0jys3m   \n",
       "\n",
       "  Freebase_character_ID Freebase_actor_ID  \n",
       "0            /m/0bgcj3x        /m/03wcfv7  \n",
       "1            /m/0bgchn4         /m/0346l4  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(characters))\n",
    "characters.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"23890098\\tShlykov, a hard-working taxi driver and Lyosha, a saxophonist, develop a bizarre love-hate relationship, and despite their prejudices, realize they aren't so different after all.\\n\""
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(summaries))\n",
    "summaries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem of date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typo in the release date of the movie, but this movie is not in characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.loc[movies.Movie_release_date == '1010-12-02','Movie_release_date'] = '2010-12-02'\n",
    "characters.loc[characters.Movie_release_date == '1010-12-02','Movie_release_date'] = '2010-12-02'\n",
    "characters[characters.Actor_date_of_birth == '2050'] = '1971'\n",
    "characters = characters.drop(characters[characters.Actor_date_of_birth < '1500'].index)\n",
    "characters = characters.drop(characters[characters.Actor_date_of_birth > '2030'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format of movie languages, genres and country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the format of languages, genres, country columns to a simpler format (in term of utilisation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_multiple(chain,deb,step):\n",
    "    '''Split the chain of characters at each \" encountered, and keep only the element in deb +i*step'''\n",
    "    res = chain.split('\"')[deb::step]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.loc[:,'Movie_genres'] = movies.Movie_genres.apply(format_multiple,deb=3,step=4)\n",
    "movies.loc[:,'Movie_countries'] = movies.Movie_countries.apply(format_multiple,deb=3,step=4)\n",
    "movies.loc[:,'Movie_languages'] = movies.Movie_languages.apply(format_multiple,deb=3,step=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13866 movies without Movie_languages (16.96% of the dataset)\n",
      "8154 movies without Movie_countries (9.98% of the dataset)\n",
      "2294 movies without Movie_genres (2.81% of the dataset)\n"
     ]
    }
   ],
   "source": [
    "keys = ['Movie_languages','Movie_countries','Movie_genres']\n",
    "for key in keys:\n",
    "    nb = len(movies[movies[key].apply(len) == 0])\n",
    "    print('{nb} movies without {key} ({percentage:.2f}% of the dataset)'.format(nb=nb,key=key, percentage=nb*100/len(movies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format for dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our study, we only keep the years from the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.Movie_release_date = pd.to_datetime(movies.Movie_release_date,format='%Y-%m-%d').dt.year\n",
    "characters.Movie_release_date = pd.to_datetime(characters.Movie_release_date,format='%Y-%m-%d').dt.year\n",
    "characters.Actor_date_of_birth = pd.to_datetime(characters.Actor_date_of_birth,format='%Y-%m-%d',utc=True,errors='coerce').dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing the summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the `corenlp_plit_summaries` files, and exctract from it the lemmatized versions of the movies summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEMMATIZE_SUMMARIES = False # take approximately 13min to run\n",
    "if LEMMATIZE_SUMMARIES:\n",
    "    from time import time\n",
    "    import os\n",
    "    import gzip\n",
    "\n",
    "    # count the number of files in the directory\n",
    "    nb_files = 0\n",
    "    for filename in os.listdir(NLP_FOLDER):\n",
    "        path = os.path.join(NLP_FOLDER, filename)\n",
    "        nb_files += 1\n",
    "    print('Number of summaries:',nb_files)\n",
    "\n",
    "    ext = '.xml.gz'\n",
    "    dico_processed_summmaries = {}\n",
    "    regex = r'<lemma>.*?</lemma>' # expression to detect in the corenlp data <lemma>(word)</lemma>\n",
    "\n",
    "    deb = time()\n",
    "    count = 0\n",
    "\n",
    "    # iteration over the files\n",
    "    for filename in os.listdir(NLP_FOLDER):\n",
    "        path = os.path.join(NLP_FOLDER, filename)\n",
    "        id_summary = path[len(NLP_FOLDER):-len(ext)] # id of the summary = filename without extension\n",
    "        summary = ''\n",
    "\n",
    "        if os.path.isfile(path): # checking if it is a file\n",
    "            with gzip.open(path, 'rb') as f: # opening the .gz file\n",
    "                for line in f:\n",
    "                    txt = line.decode().strip() # extracte the line as txt\n",
    "                    for elt in re.finditer(regex,txt): # find all the elements like regex\n",
    "                        summary += re.split('[><]',elt.group(0))[2] + ' ' # adding only the lemmatized word\n",
    "        dico_processed_summmaries[id_summary] = summary\n",
    "        count += 1\n",
    "        # evolution of the process\n",
    "        if count%1000 == 0:\n",
    "            print('{processed}/{tot} files processed --> {perc:.1f}% ({t:.1f} seconds since deb)'.format(processed=count,tot=nb_files,perc=count/nb_files*100,t=time()-deb))\n",
    "    \n",
    "    # Pickle the file\n",
    "    with open(DATA_FOLDER + 'nlp_summaries.pkl', 'wb') as file:\n",
    "        pickle.dump(dico_processed_summmaries, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little extract of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 10000053\n",
      "Summary:\n",
      " Fur trapper Jean La B te paddle he canoe through wild water towards the settlement in order to sell a load of fur . at the settlement a steamboat be landing and the trader and he foster-child Eve , ar...\n"
     ]
    }
   ],
   "source": [
    "nlp_summaries = pd.read_pickle(DATA_FOLDER+'nlp_summaries.pkl')\n",
    "for key,value in nlp_summaries.items():\n",
    "    print('Key:',key)\n",
    "    print('Summary:\\n',value[:200]+'...')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pickle our data in order to reuse directly the cleaned data (and load it faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATION = './Data/'\n",
    "EXT = '.pkl'\n",
    "to_pickle_data = [characters,movies]\n",
    "to_pickle_name = ['characters','movies']\n",
    "for i in range(len(to_pickle_data)):\n",
    "    to_pickle_data[i].to_pickle(DESTINATION+to_pickle_name[i]+EXT)\n",
    "\n",
    "#To unpickle:\n",
    "# characters = pd.read_pickle(\"./Data/characters.pkl\") \n",
    "# movies = pd.read_pickle(\"./Data/movies.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

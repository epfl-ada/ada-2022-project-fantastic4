{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook follows the plan:\n",
    "- Import the modules\n",
    "- Import the \"basic\" data (movies and characters datasets from CMU), clean it and save it\n",
    "- Extraction of the lemmatized version of the plot summaries from the corenlp processed data\n",
    "- Processing of the summaries according to the gender\n",
    "- Loading, cleaning of IMDb dataset\n",
    "- Matching CMU and IMDb datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pierre/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/pierre/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/pierre/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/pierre/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/pierre/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/pierre/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download useful packages for nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File and folder names\n",
    "DATA_FOLDER = 'Data/'\n",
    "CHARACTER_DATASET = DATA_FOLDER + 'character.metadata.tsv'\n",
    "MOVIE_DATASET = DATA_FOLDER + 'movie.metadata.tsv'\n",
    "\n",
    "SUMMARIES_DATASET = DATA_FOLDER + 'plot_summaries.txt'\n",
    "NLP_FOLDER = DATA_FOLDER + 'corenlp_plot_summaries/'\n",
    "DEFAULT_COMPRESSION = 'gzip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data\n",
    "def load_metadata(path, column_names, header=None, low_memory=False):\n",
    "    return pd.read_table(path, header=header, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name columns\n",
    "columns_character = ['Wikipedia_movie_ID', 'Freebase_movie_ID', 'Movie_release_date', 'Character_name', 'Actor_date_of_birth', 'Actor_gender', 'Actor_height_meters', 'Actor_ethnicity_Freebase_ID', 'Actor_name', 'Actor_age_at_movie_release', 'Freebase_character_actor_map_ID', 'Freebase_character_ID', 'Freebase_actor_ID']\n",
    "columns_movie = ['Wikipedia_movie_ID', 'Freebase_movie_ID', 'Movie_name','Movie_release_date','Movie_box_office_revenue', 'Movie_runtime','Movie_languages','Movie_countries','Movie_genres' ]\n",
    "\n",
    "# Load data with correct column names\n",
    "characters = load_metadata(CHARACTER_DATASET,column_names=columns_character)\n",
    "movies = load_metadata(MOVIE_DATASET,column_names=columns_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summaries\n",
    "with open(SUMMARIES_DATASET,'r', encoding='utf-8') as file:\n",
    "    summaries = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First glimpse at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we observe the movies dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81741\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Movie_box_office_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_languages</th>\n",
       "      <th>Movie_countries</th>\n",
       "      <th>Movie_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wikipedia_movie_ID Freebase_movie_ID  \\\n",
       "0              975900         /m/03vyhn   \n",
       "1             3196793         /m/08yl5d   \n",
       "\n",
       "                                          Movie_name Movie_release_date  \\\n",
       "0                                     Ghosts of Mars         2001-08-24   \n",
       "1  Getting Away with Murder: The JonBenét Ramsey ...         2000-02-16   \n",
       "\n",
       "   Movie_box_office_revenue  Movie_runtime  \\\n",
       "0                14010832.0           98.0   \n",
       "1                       NaN           95.0   \n",
       "\n",
       "                      Movie_languages  \\\n",
       "0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "1  {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "                             Movie_countries  \\\n",
       "0  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "1  {\"/m/09c7w0\": \"United States of America\"}   \n",
       "\n",
       "                                        Movie_genres  \n",
       "0  {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  \n",
       "1  {\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(movies))\n",
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we observe the characters dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450669\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Character_name</th>\n",
       "      <th>Actor_date_of_birth</th>\n",
       "      <th>Actor_gender</th>\n",
       "      <th>Actor_height_meters</th>\n",
       "      <th>Actor_ethnicity_Freebase_ID</th>\n",
       "      <th>Actor_name</th>\n",
       "      <th>Actor_age_at_movie_release</th>\n",
       "      <th>Freebase_character_actor_map_ID</th>\n",
       "      <th>Freebase_character_ID</th>\n",
       "      <th>Freebase_actor_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Akooshay</td>\n",
       "      <td>1958-08-26</td>\n",
       "      <td>F</td>\n",
       "      <td>1.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wanda De Jesus</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/m/0bgchxw</td>\n",
       "      <td>/m/0bgcj3x</td>\n",
       "      <td>/m/03wcfv7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>Lieutenant Melanie Ballard</td>\n",
       "      <td>1974-08-15</td>\n",
       "      <td>F</td>\n",
       "      <td>1.78</td>\n",
       "      <td>/m/044038p</td>\n",
       "      <td>Natasha Henstridge</td>\n",
       "      <td>27.0</td>\n",
       "      <td>/m/0jys3m</td>\n",
       "      <td>/m/0bgchn4</td>\n",
       "      <td>/m/0346l4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wikipedia_movie_ID Freebase_movie_ID Movie_release_date  \\\n",
       "0              975900         /m/03vyhn         2001-08-24   \n",
       "1              975900         /m/03vyhn         2001-08-24   \n",
       "\n",
       "               Character_name Actor_date_of_birth Actor_gender  \\\n",
       "0                    Akooshay          1958-08-26            F   \n",
       "1  Lieutenant Melanie Ballard          1974-08-15            F   \n",
       "\n",
       "   Actor_height_meters Actor_ethnicity_Freebase_ID          Actor_name  \\\n",
       "0                 1.62                         NaN      Wanda De Jesus   \n",
       "1                 1.78                  /m/044038p  Natasha Henstridge   \n",
       "\n",
       "   Actor_age_at_movie_release Freebase_character_actor_map_ID  \\\n",
       "0                        42.0                      /m/0bgchxw   \n",
       "1                        27.0                       /m/0jys3m   \n",
       "\n",
       "  Freebase_character_ID Freebase_actor_ID  \n",
       "0            /m/0bgcj3x        /m/03wcfv7  \n",
       "1            /m/0bgchn4         /m/0346l4  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(characters))\n",
    "characters.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check the summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of plots: 42306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"23890098\\tShlykov, a hard-working taxi driver and Lyosha, a saxophonist, develop a bizarre love-hate relationship, and despite their prejudices, realize they aren't so different after all.\\n\""
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of plots:', len(summaries))\n",
    "summaries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem of dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fix typos and absurd dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.loc[movies.Movie_release_date == '1010-12-02','Movie_release_date'] = '2010-12-02'\n",
    "characters.loc[characters.Movie_release_date == '1010-12-02','Movie_release_date'] = '2010-12-02'\n",
    "characters[characters.Actor_date_of_birth == '2050'] = '1971'\n",
    "characters = characters.drop(characters[characters.Actor_date_of_birth < '1500'].index)\n",
    "characters = characters.drop(characters[characters.Actor_date_of_birth > '2030'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format of movie languages, genres and country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the format of languages, genres, country columns to a simpler format (in terms of utilisation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_multiple(chain,deb,step):\n",
    "    '''Split the chain of characters at each \" encountered, and keep only the element in deb +i*step'''\n",
    "    res = chain.split('\"')[deb::step]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.loc[:,'Movie_genres'] = movies.Movie_genres.apply(format_multiple,deb=3,step=4)\n",
    "movies.loc[:,'Movie_countries'] = movies.Movie_countries.apply(format_multiple,deb=3,step=4)\n",
    "movies.loc[:,'Movie_languages'] = movies.Movie_languages.apply(format_multiple,deb=3,step=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13866 movies without Movie_languages (16.96% of the dataset)\n",
      "8154 movies without Movie_countries (9.98% of the dataset)\n",
      "2294 movies without Movie_genres (2.81% of the dataset)\n"
     ]
    }
   ],
   "source": [
    "keys = ['Movie_languages','Movie_countries','Movie_genres']\n",
    "for key in keys:\n",
    "    nb = len(movies[movies[key].apply(len) == 0])\n",
    "    print('{nb} movies without {key} ({percentage:.2f}% of the dataset)'.format(nb=nb,key=key, percentage=nb*100/len(movies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format for dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our study, we only keep the years from the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.Movie_release_date = pd.to_datetime(movies.Movie_release_date,format='%Y-%m-%d').dt.year\n",
    "characters.Movie_release_date = pd.to_datetime(characters.Movie_release_date,format='%Y-%m-%d').dt.year\n",
    "characters.Actor_date_of_birth = pd.to_datetime(characters.Actor_date_of_birth,format='%Y-%m-%d',utc=True,errors='coerce').dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pickle our data in order to reuse directly the cleaned data (and load it faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATION = './Data/'\n",
    "EXT = '.pkl'\n",
    "to_pickle_data = [characters,movies]\n",
    "to_pickle_name = ['characters','movies']\n",
    "for i in range(len(to_pickle_data)):\n",
    "    to_pickle_data[i].to_pickle(DESTINATION+to_pickle_name[i]+EXT)\n",
    "\n",
    "# # To unpickle:\n",
    "# characters = pd.read_pickle(\"./Data/characters.pkl\") \n",
    "# movies = pd.read_pickle(\"./Data/movies.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing the summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lemmatize data (for examples *'is'* becomes *'be'*) to be able to count words better. To do so, we used the `corenlp_plot_summaries` files, and exctracted from it the lemmatized versions of the movies summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True to save the data\n",
    "LEMMATIZE_SUMMARIES = False # Takes ~7 mins to run (on i7-10875H CPU)\n",
    "\n",
    "if LEMMATIZE_SUMMARIES:\n",
    "    # Imports\n",
    "    from time import time\n",
    "    import os\n",
    "    import gzip\n",
    "    import re\n",
    "\n",
    "    # Count the number of files in the directory\n",
    "    nb_files = 0\n",
    "    for filename in os.listdir(NLP_FOLDER):\n",
    "        path = os.path.join(NLP_FOLDER, filename)\n",
    "        nb_files += 1\n",
    "    print('Number of summaries:',nb_files)\n",
    "\n",
    "    ext = '.xml.gz' # Extension name\n",
    "    dico_processed_summmaries = {} # Dictionary to store the processed summaries\n",
    "    regex = r'<lemma>.*?</lemma>' # Expression to detect in the corenlp data <lemma>(word)</lemma>\n",
    "\n",
    "    deb = time() # Start timer\n",
    "    count = 0 # Counter\n",
    "\n",
    "    # Iteration over the files\n",
    "    for filename in os.listdir(NLP_FOLDER):\n",
    "        path = os.path.join(NLP_FOLDER, filename) # Path to the file\n",
    "        id_summary = path[len(NLP_FOLDER):-len(ext)] # id of the summary = filename without extension\n",
    "        summary = '' # String to store the summary\n",
    "\n",
    "        if os.path.isfile(path): # Checking if it is a file\n",
    "            with gzip.open(path, 'rb') as f: # Opening the .gz file\n",
    "                for line in f:\n",
    "                    txt = line.decode().strip() # Extract the line as txt\n",
    "                    for elt in re.finditer(regex,txt): # Find all the elements like regex\n",
    "                        summary += re.split('[><]',elt.group(0))[2].lower() + ' ' # Adding only the lemmatized word\n",
    "        \n",
    "        # Set the summary in the dictionary and increment the counter\n",
    "        dico_processed_summmaries[id_summary] = summary\n",
    "        count += 1\n",
    "\n",
    "        # Evolution of the process\n",
    "        if count%1000 == 0:\n",
    "            print('{processed}/{tot} files processed --> {perc:.1f}% ({t:.1f} seconds since deb)'.format(processed=count,tot=nb_files,perc=count/nb_files*100,t=time()-deb))\n",
    "    \n",
    "    # Pickle the file\n",
    "    with open(DATA_FOLDER + 'nlp_summaries.pkl', 'wb') as file:\n",
    "        pickle.dump(dico_processed_summmaries, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to extract the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 10000053\n",
      "Summary:\n",
      " Fur trapper Jean La B te paddle he canoe through wild water towards the settlement in order to sell a load of fur . at the settlement a steamboat be landing and the trader and he foster-child Eve , ar...\n"
     ]
    }
   ],
   "source": [
    "# Read the pickle file\n",
    "nlp_summaries = pd.read_pickle(DATA_FOLDER+'nlp_summaries.pkl')\n",
    "\n",
    "# Observe the first lemmatized summary\n",
    "for key,value in nlp_summaries.items():\n",
    "    print('Key:',key)\n",
    "    print('Summary:\\n',value[:200]+'...')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating sentences between sexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this part is to separate sentences between sexes to do a sentimental analysis later. To do so, we check if a feminine actor or the *'she'* pronoun is present in a sentence and add them to a new file. We do the same for a male actor and the *'he'* pronoun. Note that for example the sentence *'She hates him'* will become *'she hate he'* once lemmatized, which will be put in the feminine and maculine files\n",
    "\n",
    "This approach is not perfect, since for example in the sentences 'She likes butter. Indeed, the actress loves food.', only the first one will be added. It is not perfect, but the best solution we could think of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the characters\n",
    "characters_per_film = characters.copy()\n",
    "# Put the column in their correct type and lower chars\n",
    "characters_per_film['Wikipedia_movie_ID'] = characters_per_film['Wikipedia_movie_ID'].astype(int)\n",
    "characters_per_film['Character_name'] = characters_per_film['Character_name'].astype(str).apply(lambda x: x.lower())\n",
    "# Sort the dataframe by movie ID\n",
    "characters_per_film = characters_per_film.sort_values(by=['Wikipedia_movie_ID'])\n",
    "# Drio rows where the character name or the gender is empty\n",
    "characters_per_film = characters_per_film.dropna(subset=['Character_name', 'Actor_gender'])\n",
    "# Group the dataframe by movie ID\n",
    "characters_per_film = characters_per_film.groupby('Wikipedia_movie_ID')[['Wikipedia_movie_ID', 'Character_name', 'Actor_gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>plot_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27884</th>\n",
       "      <td>330</td>\n",
       "      <td>in order to prepare the role of a important ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26866</th>\n",
       "      <td>3217</td>\n",
       "      <td>after be pull through a time portal , Ash Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28281</th>\n",
       "      <td>3333</td>\n",
       "      <td>the film follow two juxtapose family : the Nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31566</th>\n",
       "      <td>3746</td>\n",
       "      <td>-lcb- -lcb- Hatnote -rcb- -rcb- in Los Angeles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31793</th>\n",
       "      <td>3837</td>\n",
       "      <td>in the American Old West of 1874 , constructio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                    plot_lemmatized\n",
       "27884   330  in order to prepare the role of a important ol...\n",
       "26866  3217  after be pull through a time portal , Ash Will...\n",
       "28281  3333  the film follow two juxtapose family : the Nor...\n",
       "31566  3746  -lcb- -lcb- Hatnote -rcb- -rcb- in Los Angeles...\n",
       "31793  3837  in the American Old West of 1874 , constructio..."
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataframe from lemmatized summaries\n",
    "df = pd.DataFrame(list(nlp_summaries.items()), columns = ['id','plot_lemmatized'])\n",
    "# Put column in their correct type\n",
    "df['id'] = df['id'].astype(int)\n",
    "# Sort the dataframe by movie ID\n",
    "df = df.sort_values(by=['id'])\n",
    "# Show the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True to save the data\n",
    "SEPARATE_SENTENCES = False # Takes ~20 mins to run (on i7-10875H CPU)\n",
    "\n",
    "if SEPARATE_SENTENCES:\n",
    "    # Imports\n",
    "    count = 0\n",
    "    dico_male = {}\n",
    "    dico_female = {}\n",
    "    regexp = nltk.tokenize.RegexpTokenizer('\\w+')\n",
    "\n",
    "    # Loop on subgroups\n",
    "    for _, group in characters_per_film:\n",
    "        # Get the movie id\n",
    "        movie_id = group['Wikipedia_movie_ID'].iloc[0]\n",
    "        female_sentences = []\n",
    "        male_sentences = []\n",
    "\n",
    "        # Check if wikipedia movie id is in the nlp summaries\n",
    "        if movie_id in df['id'].values:\n",
    "            index = df[df['id'] == movie_id].index[0] # Take the correct index\n",
    "            plot = df['plot_lemmatized'][index] # Take the correct plot\n",
    "            sentences = plot.split('.') # Split into sentences\n",
    "            # Loop on sentences\n",
    "            for sentence in sentences:\n",
    "                tokens = regexp.tokenize(sentence)\n",
    "                # Loop on characters\n",
    "                for character in group['Character_name']:\n",
    "                    # Find the sex of the character\n",
    "                    gender = group[group['Character_name'] == character].Actor_gender.values[0]\n",
    "                    # Find potential pronouns discriminative on gender\n",
    "                    he_index = any('he' in sublist for sublist in tokens)\n",
    "                    she_index = any('she' in sublist for sublist in tokens)\n",
    "                    # Check if the pronoun or actor name is in the sentence\n",
    "                    if ((character in sentence) or she_index or he_index):\n",
    "                        # Store in dictionary depending on gender of sentence (can also be in both)\n",
    "                        if ((gender == '1') or she_index):\n",
    "                            female_sentences.append(sentence)\n",
    "                        if ((gender == '0') or he_index):\n",
    "                            male_sentences.append(sentence)\n",
    "\n",
    "        # Store in dictionary and increment counter\n",
    "        dico_male[movie_id] = male_sentences\n",
    "        dico_female[movie_id] = female_sentences\n",
    "        count += 1\n",
    "\n",
    "        # Evolution of the process\n",
    "        if count%1000 == 0:\n",
    "            print('{processed} files processed'.format(processed=count))\n",
    "\n",
    "    # Pickle the file\n",
    "    with open(DATA_FOLDER + 'male_sentences.pkl', 'wb') as file:\n",
    "        pickle.dump(dico_male, file, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "    with open(DATA_FOLDER + 'female_sentences.pkl', 'wb') as file:\n",
    "        pickle.dump(dico_female, file, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse sentiments for each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run it in the handling of data since it takes a long time to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>330</td>\n",
       "      <td>[in order to prepare the role of a important o...</td>\n",
       "      <td>in order to prepare the role of a important ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1971</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3217</td>\n",
       "      <td>[after be pull through a time portal , Ash Wil...</td>\n",
       "      <td>after be pull through a time portal , Ash Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3333</td>\n",
       "      <td>[the film follow two juxtapose family : the No...</td>\n",
       "      <td>the film follow two juxtapose family : the Nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3746</td>\n",
       "      <td>[-lcb- -lcb- Hatnote -rcb- -rcb- in Los Angele...</td>\n",
       "      <td>-lcb- -lcb- Hatnote -rcb- -rcb- in Los Angeles...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                          sentences  \\\n",
       "0   330  [in order to prepare the role of a important o...   \n",
       "1  1971                                                 []   \n",
       "2  3217  [after be pull through a time portal , Ash Wil...   \n",
       "3  3333  [the film follow two juxtapose family : the No...   \n",
       "4  3746  [-lcb- -lcb- Hatnote -rcb- -rcb- in Los Angele...   \n",
       "\n",
       "                                             summary  \n",
       "0  in order to prepare the role of a important ol...  \n",
       "1                                                     \n",
       "2  after be pull through a time portal , Ash Will...  \n",
       "3  the film follow two juxtapose family : the Nor...  \n",
       "4  -lcb- -lcb- Hatnote -rcb- -rcb- in Los Angeles...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import male sentences\n",
    "male_sentences_dict = pd.read_pickle(DATA_FOLDER + 'male_sentences.pkl')\n",
    "# Form a dataframe\n",
    "male_sentences = pd.DataFrame(list(male_sentences_dict.items()), columns = ['id','sentences'])\n",
    "# Create a new column that reconstructs the summary from the lemmatized sentences\n",
    "male_sentences['summary'] = male_sentences['sentences'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Import female sentences\n",
    "female_sentences_dict = pd.read_pickle(DATA_FOLDER + 'female_sentences.pkl')\n",
    "# Form a dataframe\n",
    "female_sentences = pd.DataFrame(list(female_sentences_dict.items()), columns = ['id','sentences'])\n",
    "# Create a new column that reconstructs the summary from the lemmatized sentences\n",
    "female_sentences['summary'] = female_sentences['sentences'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Show the first 5 rows of male sentences\n",
    "male_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_SENTIMENTS = False # Takes ~41 mins to run (on i7-10875H CPU)\n",
    "\n",
    "if SAVE_SENTIMENTS:\n",
    "    # Use nltk Vader to get the sentiment of the sentences\n",
    "    analyzer =  nltk.sentiment.SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Apply sentiments to plots\n",
    "    male_sentences['polarity'] = male_sentences['summary'].apply(lambda x: analyzer.polarity_scores(x))\n",
    "    female_sentences['polarity'] = female_sentences['summary'].apply(lambda x: analyzer.polarity_scores(x))\n",
    "\n",
    "    # Pickle the file\n",
    "    with open(DATA_FOLDER + 'male_sentiments.pkl', 'wb') as file:\n",
    "        pickle.dump(male_sentences, file, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "    with open(DATA_FOLDER + 'female_sentiments.pkl', 'wb') as file:\n",
    "        pickle.dump(female_sentences, file, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enriching the CMU dataset with IMDb dataset and movie-stats\n",
    "\n",
    "## Loading the data and first glimpse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the most useful datasets from IMDb\n",
    "TITLE_BASICS_DATASET = DATA_FOLDER + 'title.basics.tsv.gz'\n",
    "TITLE_RATINGS_DATASET = DATA_FOLDER + 'title.ratings.tsv.gz'\n",
    "#Load movie-stats, a dataset generated from IMDb movies\n",
    "MOVIE_STATS = DATA_FOLDER + 'movie-stats.csv'\n",
    "\n",
    "columns_title_basics = ['tconst', 'titleType', 'primaryTitle', 'originalTitle', 'isAdult', 'startYear', 'endYear', 'runtimeMinutes', 'genres']\n",
    "columns_ratings = ['tconstIdentifier', 'averageRating', 'numVotes']\n",
    "\n",
    "DESTINATION = './Data/'\n",
    "MATCHING_TABLE = DESTINATION + 'matching_table.pkl'\n",
    "\n",
    "CLEAN_DATA = False # True to clean again the data, False to use the already pickled data\n",
    "MATCH_DATA = False # True to match on film names, False to use the matching table already computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_DATA:\n",
    "    #Load title_basics\n",
    "    title_basics = load_metadata(TITLE_BASICS_DATASET, column_names=columns_title_basics)\n",
    "    print(\"length of title_basics: \", len(title_basics))\n",
    "    title_basics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_DATA:\n",
    "    #Load title_ratings\n",
    "    ratings = load_metadata(TITLE_RATINGS_DATASET, column_names=columns_ratings)\n",
    "    print(\"length of ratings: \", len(ratings))\n",
    "    ratings.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_DATA:\n",
    "    #Load movie-stats\n",
    "    movie_stats = pd.read_csv(MOVIE_STATS, header = 8)\n",
    "    print(\"length of movie_stats: \", len(movie_stats))\n",
    "    movie_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_DATA:\n",
    "    #Create a new table with only titleType=movies (get rid of videos, tvshows, tvepisodes and short)\n",
    "    title_basics_movies = title_basics[title_basics[\"titleType\"] == \"movie\"]\n",
    "    #Remove the endYear column since movies are not concerned by thats\n",
    "    title_basics_movies_cleaned = title_basics_movies.drop(columns='endYear')\n",
    "    title_basics_movies_cleaned.replace('\\\\N',np.NaN,inplace=True) # replace \\\\N by NaN\n",
    "    # datetime format for dates\n",
    "    title_basics_movies_cleaned.startYear = pd.to_datetime(title_basics_movies_cleaned.startYear,format='%Y').dt.year \n",
    "    title_basics_movies_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_DATA:\n",
    "    #Drop the first row which represents the titles of the columns\n",
    "    #Careful: execute only once, otherwise it will delete the first row each time!\n",
    "    ratings_cleaned = ratings.drop(index=ratings.index[0], axis=0) \n",
    "    print(\"length of ratings_cleaned: \", len(ratings_cleaned))\n",
    "    ratings_cleaned.replace('\\\\N',np.NaN,inplace=True) # replace \\\\N by NaN\n",
    "    #Check if there are NaN values in the dataset\n",
    "    print('Number of NaN in the ratings dataset: \\n',ratings_cleaned.isnull().sum())\n",
    "    ratings_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_DATA:\n",
    "    #Check if there are NaN values in the dataset\n",
    "    print('Number of NaN in the movie-stats dataset: \\n', movie_stats.isnull().sum())\n",
    "    #Remove useless columns\n",
    "    movie_stats_cleaned = movie_stats.drop(columns=['rating', 'released'])\n",
    "    #Remove rows where budget is NaN because we use movie-stats dataset to get information on budget\n",
    "    movie_stats_cleaned.dropna(subset=['budget'], inplace=True)\n",
    "    movie_stats_cleaned.head()\n",
    "    print(\"length of movie_stats_cleaned: \", len(movie_stats_cleaned))\n",
    "    print('Number of NaN in the cleaned movie-stats dataset: \\n', movie_stats_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATION = './Data/'\n",
    "EXT = '.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_DATA:\n",
    "    #Pickle the data\n",
    "    to_pickle_data = title_basics_movies_cleaned\n",
    "    to_pickle_name = 'IMDb_title_movies'\n",
    "    to_pickle_data.to_pickle(DESTINATION+to_pickle_name+EXT)\n",
    "\n",
    "if not CLEAN_DATA: # for testing part\n",
    "    # load already pickled data\n",
    "    title_basics_movies_cleaned = pd.read_pickle(\"./Data/IMDb_title_movies.pkl\")\n",
    "    title_basics_movies_cleaned.startYear = pd.to_datetime(title_basics_movies_cleaned.startYear,format='%Y').dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_DATA:\n",
    "    #Pickle the data\n",
    "    to_pickle_data = ratings_cleaned\n",
    "    to_pickle_name = 'IMDb_ratings'\n",
    "    to_pickle_data.to_pickle(DESTINATION+to_pickle_name+EXT)\n",
    "\n",
    "if not CLEAN_DATA: # for testing part\n",
    "    # load already pickled data\n",
    "    ratings_cleaned = pd.read_pickle(\"./Data/IMDb_ratings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLEAN_DATA:\n",
    "    #Pickle the data\n",
    "    to_pickle_data = movie_stats_cleaned\n",
    "    to_pickle_name = 'movie-stats_budget'\n",
    "    to_pickle_data.to_pickle(DESTINATION+to_pickle_name+EXT)\n",
    "\n",
    "if not CLEAN_DATA: # for testing part\n",
    "    # load already pickled data\n",
    "    movie_stats_cleaned = pd.read_pickle(\"./Data/movie-stats_budget.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching IMDb and CMU films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "      <th>score</th>\n",
       "      <th>votes</th>\n",
       "      <th>director</th>\n",
       "      <th>writer</th>\n",
       "      <th>star</th>\n",
       "      <th>country</th>\n",
       "      <th>budget</th>\n",
       "      <th>gross</th>\n",
       "      <th>company</th>\n",
       "      <th>runtime\\</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shining</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1980</td>\n",
       "      <td>8.4</td>\n",
       "      <td>927000.0</td>\n",
       "      <td>Stanley Kubrick</td>\n",
       "      <td>Stephen King</td>\n",
       "      <td>Jack Nicholson</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>19000000.0</td>\n",
       "      <td>46998772.0</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>146.0\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Blue Lagoon</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>1980</td>\n",
       "      <td>5.8</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Randal Kleiser</td>\n",
       "      <td>Henry De Vere Stacpoole</td>\n",
       "      <td>Brooke Shields</td>\n",
       "      <td>United States</td>\n",
       "      <td>4500000.0</td>\n",
       "      <td>58853106.0</td>\n",
       "      <td>Columbia Pictures</td>\n",
       "      <td>104.0\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back</td>\n",
       "      <td>Action</td>\n",
       "      <td>1980</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>Irvin Kershner</td>\n",
       "      <td>Leigh Brackett</td>\n",
       "      <td>Mark Hamill</td>\n",
       "      <td>United States</td>\n",
       "      <td>18000000.0</td>\n",
       "      <td>538375067.0</td>\n",
       "      <td>Lucasfilm</td>\n",
       "      <td>124.0\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airplane!</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1980</td>\n",
       "      <td>7.7</td>\n",
       "      <td>221000.0</td>\n",
       "      <td>Jim Abrahams</td>\n",
       "      <td>Jim Abrahams</td>\n",
       "      <td>Robert Hays</td>\n",
       "      <td>United States</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>83453539.0</td>\n",
       "      <td>Paramount Pictures</td>\n",
       "      <td>88.0\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caddyshack</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1980</td>\n",
       "      <td>7.3</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>Harold Ramis</td>\n",
       "      <td>Brian Doyle-Murray</td>\n",
       "      <td>Chevy Chase</td>\n",
       "      <td>United States</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>39846344.0</td>\n",
       "      <td>Orion Pictures</td>\n",
       "      <td>98.0\\</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             name      genre  year  score  \\\n",
       "0                                     The Shining      Drama  1980    8.4   \n",
       "1                                 The Blue Lagoon  Adventure  1980    5.8   \n",
       "2  Star Wars: Episode V - The Empire Strikes Back     Action  1980    8.7   \n",
       "3                                       Airplane!     Comedy  1980    7.7   \n",
       "4                                      Caddyshack     Comedy  1980    7.3   \n",
       "\n",
       "       votes         director                   writer            star  \\\n",
       "0   927000.0  Stanley Kubrick             Stephen King  Jack Nicholson   \n",
       "1    65000.0   Randal Kleiser  Henry De Vere Stacpoole  Brooke Shields   \n",
       "2  1200000.0   Irvin Kershner           Leigh Brackett     Mark Hamill   \n",
       "3   221000.0     Jim Abrahams             Jim Abrahams     Robert Hays   \n",
       "4   108000.0     Harold Ramis       Brian Doyle-Murray     Chevy Chase   \n",
       "\n",
       "          country      budget        gross             company runtime\\  \n",
       "0  United Kingdom  19000000.0   46998772.0        Warner Bros.   146.0\\  \n",
       "1   United States   4500000.0   58853106.0   Columbia Pictures   104.0\\  \n",
       "2   United States  18000000.0  538375067.0           Lucasfilm   124.0\\  \n",
       "3   United States   3500000.0   83453539.0  Paramount Pictures    88.0\\  \n",
       "4   United States   6000000.0   39846344.0      Orion Pictures    98.0\\  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_stats_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconstIdentifier</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>5.8</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>5.6</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tconstIdentifier averageRating numVotes\n",
       "1        tt0000001           5.7     1922\n",
       "2        tt0000002           5.8      259\n",
       "3        tt0000003           6.5     1734\n",
       "4        tt0000004           5.6      174\n",
       "5        tt0000005           6.2     2545"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We match the movies from one dataset to the films on the other dataset on the movie name, as the ids are different.\n",
    "\n",
    "In order to avoid mismatched pairs due to a little variation in the titles, we matched films of the same year, with almost identical titles (via Jaccard distance). We create a dictionnary that matches the index of matched films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8328\n",
      "541993\n"
     ]
    }
   ],
   "source": [
    "copy_IMDb = title_basics_movies_cleaned.copy()\n",
    "copy_IMDb = copy_IMDb[copy_IMDb.startYear >= 1910]\n",
    "copy_CMU = movies.copy()\n",
    "copy_CMU.dropna(subset=['Movie_box_office_revenue', 'Movie_release_date'], inplace=True)\n",
    "copy_IMDb.dropna(subset= ['startYear'], inplace=True)\n",
    "print(len(copy_CMU)) # 8328\n",
    "print(len(copy_IMDb)) # 541993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "common_words = {'a','an','and','the','of','at','in'}\n",
    "punctuation = {'.',',','!',';','?',''}\n",
    "def compare(df1,df2,col1_title,col2_title,col1_year,col2_year,threshold = 0.8, delta_year=1):\n",
    "        matched = {}\n",
    "        for idx1,row1 in df1.iterrows():\n",
    "            title1 = set(re.split('[ :,]',row1[col1_title].lower()))\n",
    "            title1 = title1.difference(punctuation)\n",
    "            y1 = row1[col1_year]\n",
    "            print(title1,y1)\n",
    "            #for idx2,row2 in df2[df2[col2_year].isin([y1-delta_year+i for i in range(delta_year*2)])].iterrows():\n",
    "            for idx2,row2 in df2[df2[col2_year]==y1].iterrows():\n",
    "                title2 = set(re.split('[ :,]',row2[col2_title].lower()))\n",
    "                title2 = title2.difference(punctuation)\n",
    "                if len(title1 & title2)/(len(title1 | title2)) > threshold:\n",
    "                    print(title2)\n",
    "                    print('ok')\n",
    "                    try:\n",
    "                        matched[idx1].append(idx2)\n",
    "                    except KeyError:\n",
    "                        matched[idx1] = [idx2]\n",
    "        return matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATCH_DATA:\n",
    "    from time import time\n",
    "    deb = time()\n",
    "    matched = compare(copy_CMU,copy_IMDb, 'Movie_name', 'primaryTitle', 'Movie_release_date', 'startYear')\n",
    "    end = time()\n",
    "    print('Time of execution:', end-deb) # 2360s\n",
    "    matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATCH_DATA:\n",
    "    # save the matching table\n",
    "    with open(MATCHING_TABLE, 'wb') as file:\n",
    "        pickle.dump(matched, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    matched = pd.read_pickle(MATCHING_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 duplicates (1.16% of all matchings)\n"
     ]
    }
   ],
   "source": [
    "doublons = {}\n",
    "for match in matched:\n",
    "    if len(matched[match]) > 1:\n",
    "        doublons[match] = matched[match]\n",
    "print('{nb} duplicates ({per:.2f}% of all matchings)'.format(nb=len(doublons), per=len(doublons)/len(matched)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3391684    The Way  VS  The Way\n",
      "4535866    The Way  VS  The Way\n",
      "Name: primaryTitle, dtype: object\n",
      "58112    Harlow  VS  Harlow\n",
      "58113    Harlow  VS  Harlow\n",
      "Name: primaryTitle, dtype: object\n",
      "88939     Down and Out in Beverly Hills  VS  Down and Ou...\n",
      "176644    Down and Out in Beverly Hills  VS  In and Out ...\n",
      "Name: primaryTitle, dtype: object\n",
      "368686     The Dying Gaul  VS  The Dying Gaul\n",
      "4613260    The Dying Gaul  VS  The Dying Gaul\n",
      "Name: primaryTitle, dtype: object\n",
      "88104      Sweet Dreams  VS  Sweet Dreams\n",
      "7993798    Sweet Dreams  VS  Sweet Dreams\n",
      "Name: primaryTitle, dtype: object\n",
      "97951    My Blue Heaven  VS  My Blue Heaven\n",
      "97952    My Blue Heaven  VS  My Blue Heaven\n",
      "Name: primaryTitle, dtype: object\n",
      "86067      Runaway  VS  Runaway\n",
      "7811004    Runaway  VS  Runaway\n",
      "Name: primaryTitle, dtype: object\n",
      "3772516    Super  VS  Super\n",
      "4745142    Super  VS  Super\n",
      "Name: primaryTitle, dtype: object\n",
      "3264408    White Night  VS  White Night\n",
      "3886728    White Night  VS  White Night\n",
      "Name: primaryTitle, dtype: object\n",
      "1552502    One Week  VS  One Week\n",
      "2849606    One Week  VS  One Week\n",
      "Name: primaryTitle, dtype: object\n",
      "2306819    Free Man  VS  Man Free\n",
      "4716970    Free Man  VS  Free Man\n",
      "Name: primaryTitle, dtype: object\n",
      "113879     The Hunchback of Notre Dame  VS  The Hunchback...\n",
      "9309223    The Hunchback of Notre Dame  VS  The Hunchback...\n",
      "Name: primaryTitle, dtype: object\n",
      "323924    The Missing  VS  The Missing\n",
      "368227    The Missing  VS  The Missing\n",
      "Name: primaryTitle, dtype: object\n",
      "1049763    Alice in Wonderland  VS  Alice in Wonderland\n",
      "5255156    Alice in Wonderland  VS  Alice in Wonderland\n",
      "Name: primaryTitle, dtype: object\n",
      "1672433    Burlesque  VS  Burlesque\n",
      "4178745    Burlesque  VS  Burlesque\n",
      "Name: primaryTitle, dtype: object\n",
      "389961    The Guardian  VS  The Guardian\n",
      "443993    The Guardian  VS  The Guardian\n",
      "Name: primaryTitle, dtype: object\n",
      "4392116    Black and White  VS  Black and White\n",
      "4705698    Black and White  VS  White and Black\n",
      "Name: primaryTitle, dtype: object\n",
      "170616    Gossip  VS  Gossip\n",
      "228201    Gossip  VS  Gossip\n",
      "Name: primaryTitle, dtype: object\n",
      "4460137    The Artist  VS  The Artist\n",
      "4786866    The Artist  VS  The Artist\n",
      "Name: primaryTitle, dtype: object\n",
      "371888    Malevolence  VS  Malevolence\n",
      "372780    Malevolence  VS  Malevolence\n",
      "Name: primaryTitle, dtype: object\n",
      "386153    Chaos  VS  Chaos\n",
      "389139    Chaos  VS  Chaos\n",
      "Name: primaryTitle, dtype: object\n",
      "4176241    What to Expect When You're Expecting  VS  What...\n",
      "6062867    What to Expect When You're Expecting  VS  What...\n",
      "Name: primaryTitle, dtype: object\n",
      "2804359    Turning Point  VS  Turning Point\n",
      "3617359    Turning Point  VS  Turning Point\n",
      "Name: primaryTitle, dtype: object\n",
      "3821221    Sacrifice  VS  Sacrifice\n",
      "4614842    Sacrifice  VS  Sacrifice\n",
      "Name: primaryTitle, dtype: object\n",
      "111471     Panther  VS  Panther\n",
      "2961417    Panther  VS  Panther\n",
      "Name: primaryTitle, dtype: object\n",
      "4596044    Weekend  VS  Weekend\n",
      "4727953    Weekend  VS  Weekend\n",
      "4975392    Weekend  VS  Weekend\n",
      "Name: primaryTitle, dtype: object\n",
      "94758    Black Rain  VS  Black Rain\n",
      "95499    Black Rain  VS  Black Rain\n",
      "Name: primaryTitle, dtype: object\n",
      "294778     Bobby  VS  Bobby\n",
      "8740960    Bobby  VS  Bobby\n",
      "Name: primaryTitle, dtype: object\n",
      "2171378    Leap Year  VS  Leap Year\n",
      "3909194    Leap Year  VS  Leap Year\n",
      "Name: primaryTitle, dtype: object\n",
      "386153    Chaos  VS  Chaos\n",
      "389139    Chaos  VS  Chaos\n",
      "Name: primaryTitle, dtype: object\n",
      "1321292    The Wave  VS  The Wave\n",
      "4579006    The Wave  VS  The Wave\n",
      "Name: primaryTitle, dtype: object\n",
      "325833    Hostage  VS  Hostage\n",
      "447132    Hostage  VS  Hostage\n",
      "Name: primaryTitle, dtype: object\n",
      "2768022    Cyrus  VS  Cyrus\n",
      "2815215    Cyrus  VS  Cyrus\n",
      "Name: primaryTitle, dtype: object\n",
      "473695     The 11th Hour  VS  The 11th Hour\n",
      "1208970    The 11th Hour  VS  The 11th Hour\n",
      "Name: primaryTitle, dtype: object\n",
      "963369     Ghost Town  VS  Ghost Town\n",
      "4291501    Ghost Town  VS  Ghost Town\n",
      "Name: primaryTitle, dtype: object\n",
      "130384    Ride with the Devil  VS  Ride with the Devil\n",
      "230712    Ride with the Devil  VS  Ride with the Devil\n",
      "Name: primaryTitle, dtype: object\n",
      "301266    The In-Laws  VS  The In-Laws\n",
      "341695    The In-Laws  VS  The In-Laws\n",
      "Name: primaryTitle, dtype: object\n",
      "982165     Hansel and Gretel  VS  Hansel and Gretel\n",
      "2346915    Hansel and Gretel  VS  Hansel and Gretel\n",
      "Name: primaryTitle, dtype: object\n",
      "158716     Limbo  VS  Limbo\n",
      "7520453    Limbo  VS  Limbo\n",
      "Name: primaryTitle, dtype: object\n",
      "1458924    Wide Awake  VS  Wide Awake\n",
      "1679369    Wide Awake  VS  Wide Awake\n",
      "Name: primaryTitle, dtype: object\n",
      "111534     Pocahontas  VS  Pocahontas\n",
      "8959947    Pocahontas  VS  Pocahontas\n",
      "Name: primaryTitle, dtype: object\n",
      "2341156    High School  VS  High School\n",
      "3532540    High School  VS  High School\n",
      "Name: primaryTitle, dtype: object\n",
      "2171399    Mother  VS  Mother\n",
      "4033447    Mother  VS  Mother\n",
      "Name: primaryTitle, dtype: object\n",
      "2587554    Last Night  VS  Last Night\n",
      "4642477    Last Night  VS  Last Night\n",
      "Name: primaryTitle, dtype: object\n",
      "96319     True Love  VS  True Love\n",
      "148620    True Love  VS  True Love\n",
      "Name: primaryTitle, dtype: object\n",
      "3999434    A Better Life  VS  A Better Life\n",
      "5219390    A Better Life  VS  A Better Life\n",
      "Name: primaryTitle, dtype: object\n",
      "2479106    The Tempest  VS  The Tempest\n",
      "4520160    The Tempest  VS  The Tempest\n",
      "Name: primaryTitle, dtype: object\n",
      "861585    M  VS  M\n",
      "957538    M  VS  M\n",
      "Name: primaryTitle, dtype: object\n",
      "4482406    Mirror Mirror  VS  Mirror Mirror\n",
      "5540652           Mirror Mirror  VS  Mirror\n",
      "Name: primaryTitle, dtype: object\n",
      "945111     Old Dogs  VS  Old Dogs\n",
      "1691732    Old Dogs  VS  Old Dogs\n",
      "Name: primaryTitle, dtype: object\n",
      "347286     The Box  VS  The Box\n",
      "3005336    The Box  VS  The Box\n",
      "Name: primaryTitle, dtype: object\n",
      "98209     Revenge  VS  Revenge\n",
      "100177    Revenge  VS  Revenge\n",
      "178878    Revenge  VS  Revenge\n",
      "Name: primaryTitle, dtype: object\n",
      "2925462    I'm Still Here  VS  I'm Still Here\n",
      "4566089    I'm Still Here  VS  I'm Still Here\n",
      "Name: primaryTitle, dtype: object\n",
      "117722     A Bug's Life  VS  A Bug's Life\n",
      "7893069    A Bug's Life  VS  A Bug's Life\n",
      "Name: primaryTitle, dtype: object\n",
      "401464    Dreamer  VS  Dreamer\n",
      "468796    Dreamer  VS  Dreamer\n",
      "Name: primaryTitle, dtype: object\n",
      "274677    Scorched  VS  Scorched\n",
      "356384    Scorched  VS  Scorched\n",
      "Name: primaryTitle, dtype: object\n",
      "95287    Happy Together  VS  Happy Together\n",
      "96462    Happy Together  VS  Happy Together\n",
      "Name: primaryTitle, dtype: object\n",
      "856445    The Mist  VS  The Mist\n",
      "958212    The Mist  VS  The Mist\n",
      "Name: primaryTitle, dtype: object\n",
      "348248    Beyond the Sea  VS  Beyond the Sea\n",
      "366322    Beyond the Sea  VS  Beyond the Sea\n",
      "Name: primaryTitle, dtype: object\n",
      "100308     Paradise  VS  Paradise\n",
      "8482062    Paradise  VS  Paradise\n",
      "Name: primaryTitle, dtype: object\n",
      "45944     The Black Knight  VS  The Black Knight\n",
      "261941    The Black Knight  VS  The Black Knight\n",
      "Name: primaryTitle, dtype: object\n",
      "2743055    Frozen  VS  Frozen\n",
      "4287367    Frozen  VS  Frozen\n",
      "Name: primaryTitle, dtype: object\n",
      "5545932    Stone  VS  Stone\n",
      "5968993    Stone  VS  Stone\n",
      "Name: primaryTitle, dtype: object\n",
      "114828    Scream  VS  Scream\n",
      "170730    Scream  VS  Scream\n",
      "Name: primaryTitle, dtype: object\n",
      "308476      2 Fast 2 Furious  VS  2 Fast 2 Furious\n",
      "3130196    2 Fast 2 Furious  VS  2 Fast, 2 Furious\n",
      "Name: primaryTitle, dtype: object\n",
      "4250549    Abduction  VS  Abduction\n",
      "6029895    Abduction  VS  Abduction\n",
      "Name: primaryTitle, dtype: object\n",
      "1428982    Quarantine  VS  Quarantine\n",
      "8372019    Quarantine  VS  Quarantine\n",
      "Name: primaryTitle, dtype: object\n",
      "117287    Soldier  VS  Soldier\n",
      "202982    Soldier  VS  Soldier\n",
      "Name: primaryTitle, dtype: object\n",
      "779149    Asylum  VS  Asylum\n",
      "829238    Asylum  VS  Asylum\n",
      "Name: primaryTitle, dtype: object\n",
      "5287187    Deranged  VS  Deranged\n",
      "5575999    Deranged  VS  Deranged\n",
      "Name: primaryTitle, dtype: object\n",
      "151877    Last Night  VS  Last Night\n",
      "273082    Last Night  VS  Last Night\n",
      "Name: primaryTitle, dtype: object\n",
      "5871200    Over My Dead Body  VS  Over My Dead Body\n",
      "5948471    Over My Dead Body  VS  Over My Dead Body\n",
      "Name: primaryTitle, dtype: object\n",
      "1183940    The Bounty Hunter  VS  The Bounty Hunter\n",
      "3556592    The Bounty Hunter  VS  The Bounty Hunter\n",
      "Name: primaryTitle, dtype: object\n",
      "100920    White Fang  VS  White Fang\n",
      "283607    White Fang  VS  White Fang\n",
      "Name: primaryTitle, dtype: object\n",
      "116810    Men with Guns  VS  Men with Guns\n",
      "116811    Men with Guns  VS  Men with Guns\n",
      "Name: primaryTitle, dtype: object\n",
      "97499     Havana  VS  Havana\n",
      "267902    Havana  VS  Havana\n",
      "Name: primaryTitle, dtype: object\n",
      "4841129    Gone  VS  Gone\n",
      "5743936    Gone  VS  Gone\n",
      "Name: primaryTitle, dtype: object\n",
      "102064    Hero  VS  Hero\n",
      "239824    Hero  VS  Hero\n",
      "Name: primaryTitle, dtype: object\n",
      "3023322    Upside Down  VS  Upside Down\n",
      "5364699    Upside Down  VS  Upside Down\n",
      "Name: primaryTitle, dtype: object\n",
      "4568054    The Hunter  VS  The Hunter\n",
      "4994823    The Hunter  VS  The Hunter\n",
      "Name: primaryTitle, dtype: object\n",
      "2273700    The Future  VS  The Future\n",
      "7511404    The Future  VS  The Future\n",
      "Name: primaryTitle, dtype: object\n",
      "97110    Lambada  VS  Lambada\n",
      "97713    Lambada  VS  Lambada\n",
      "Name: primaryTitle, dtype: object\n",
      "92618    The Big Blue  VS  The Big Blue\n",
      "93120    The Big Blue  VS  The Big Blue\n",
      "Name: primaryTitle, dtype: object\n",
      "109821     Apollo 13  VS  Apollo 13\n",
      "7840817    Apollo 13  VS  Apollo 13\n",
      "Name: primaryTitle, dtype: object\n",
      "4462863    First Love  VS  First Love\n",
      "5137898    First Love  VS  First Love\n",
      "Name: primaryTitle, dtype: object\n",
      "2002829    Adam  VS  Adam\n",
      "3395157    Adam  VS  Adam\n",
      "Name: primaryTitle, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for cmu,imdbs in doublons.items():\n",
    "    print(copy_CMU.loc[cmu,'Movie_name'] + '  VS  ' + copy_IMDb.loc[imdbs,'primaryTitle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many duplicated matched are juste films with the same name (and same year), so probably duplicated films in the database.\n",
    "\n",
    "Some are similar titles but the order of words is changed (e.g \"Black and White\" corresponding to \"Black and White\" and \"White and Black\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the datasets\n",
    "\n",
    "As only $1.16\\%$ of the matchings are duplicated, we will simply drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7356\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Movie_box_office_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_languages</th>\n",
       "      <th>Movie_countries</th>\n",
       "      <th>Movie_genres</th>\n",
       "      <th>IMDb_index</th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Thriller, Science Fiction, Horror, Adventure,...</td>\n",
       "      <td>218707</td>\n",
       "      <td>tt0228333</td>\n",
       "      <td>movie</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>98</td>\n",
       "      <td>Action,Horror,Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10408933</td>\n",
       "      <td>/m/02qc0j7</td>\n",
       "      <td>Alexander's Ragtime Band</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Musical, Comedy, Black-and-white]</td>\n",
       "      <td>29325</td>\n",
       "      <td>tt0029852</td>\n",
       "      <td>movie</td>\n",
       "      <td>Alexander's Ragtime Band</td>\n",
       "      <td>Alexander's Ragtime Band</td>\n",
       "      <td>0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>106</td>\n",
       "      <td>Drama,Music,Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171005</td>\n",
       "      <td>/m/016ywb</td>\n",
       "      <td>Henry V</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>10161099.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[Costume drama, War film, Epic, Period piece, ...</td>\n",
       "      <td>95308</td>\n",
       "      <td>tt0097499</td>\n",
       "      <td>movie</td>\n",
       "      <td>Henry V</td>\n",
       "      <td>Henry V</td>\n",
       "      <td>0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>137</td>\n",
       "      <td>Biography,Drama,History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77856</td>\n",
       "      <td>/m/0kcn7</td>\n",
       "      <td>Mary Poppins</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>102272727.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Children's/Family, Musical, Fantasy, Comedy, ...</td>\n",
       "      <td>57208</td>\n",
       "      <td>tt0058331</td>\n",
       "      <td>movie</td>\n",
       "      <td>Mary Poppins</td>\n",
       "      <td>Mary Poppins</td>\n",
       "      <td>0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>139</td>\n",
       "      <td>Comedy,Family,Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156558</td>\n",
       "      <td>/m/014k4y</td>\n",
       "      <td>Baby Boy</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>29381649.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Crime Fiction, Drama, Coming of age]</td>\n",
       "      <td>244954</td>\n",
       "      <td>tt0255819</td>\n",
       "      <td>movie</td>\n",
       "      <td>Baby Boy</td>\n",
       "      <td>Baby Boy</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>130</td>\n",
       "      <td>Crime,Drama,Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wikipedia_movie_ID Freebase_movie_ID                Movie_name  \\\n",
       "0              975900         /m/03vyhn            Ghosts of Mars   \n",
       "1            10408933        /m/02qc0j7  Alexander's Ragtime Band   \n",
       "2              171005         /m/016ywb                   Henry V   \n",
       "3               77856          /m/0kcn7              Mary Poppins   \n",
       "4              156558         /m/014k4y                  Baby Boy   \n",
       "\n",
       "   Movie_release_date  Movie_box_office_revenue  Movie_runtime  \\\n",
       "0              2001.0                14010832.0           98.0   \n",
       "1              1938.0                 3600000.0          106.0   \n",
       "2              1989.0                10161099.0          137.0   \n",
       "3              1964.0               102272727.0          139.0   \n",
       "4              2001.0                29381649.0          123.0   \n",
       "\n",
       "      Movie_languages             Movie_countries  \\\n",
       "0  [English Language]  [United States of America]   \n",
       "1  [English Language]  [United States of America]   \n",
       "2  [English Language]            [United Kingdom]   \n",
       "3  [English Language]  [United States of America]   \n",
       "4  [English Language]  [United States of America]   \n",
       "\n",
       "                                        Movie_genres  IMDb_index     tconst  \\\n",
       "0  [Thriller, Science Fiction, Horror, Adventure,...      218707  tt0228333   \n",
       "1                 [Musical, Comedy, Black-and-white]       29325  tt0029852   \n",
       "2  [Costume drama, War film, Epic, Period piece, ...       95308  tt0097499   \n",
       "3  [Children's/Family, Musical, Fantasy, Comedy, ...       57208  tt0058331   \n",
       "4              [Crime Fiction, Drama, Coming of age]      244954  tt0255819   \n",
       "\n",
       "  titleType              primaryTitle             originalTitle isAdult  \\\n",
       "0     movie            Ghosts of Mars            Ghosts of Mars       0   \n",
       "1     movie  Alexander's Ragtime Band  Alexander's Ragtime Band       0   \n",
       "2     movie                   Henry V                   Henry V       0   \n",
       "3     movie              Mary Poppins              Mary Poppins       0   \n",
       "4     movie                  Baby Boy                  Baby Boy       0   \n",
       "\n",
       "   startYear runtimeMinutes                   genres  \n",
       "0     2001.0             98     Action,Horror,Sci-Fi  \n",
       "1     1938.0            106      Drama,Music,Musical  \n",
       "2     1989.0            137  Biography,Drama,History  \n",
       "3     1964.0            139    Comedy,Family,Fantasy  \n",
       "4     2001.0            130      Crime,Drama,Romance  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cmu,imdbs in matched.items():\n",
    "    if cmu not in doublons:\n",
    "        copy_CMU.loc[cmu,'IMDb_index'] = imdbs[0]\n",
    "copy_IMDb['IMDb_index'] = copy_IMDb.index\n",
    "copy_CMU.dropna(subset=['IMDb_index'],inplace=True)\n",
    "copy_CMU['IMDb_index'] = copy_CMU['IMDb_index'].astype('int64')\n",
    "merge_df = pd.merge(copy_CMU, copy_IMDb, on = 'IMDb_index', how = \"inner\")\n",
    "print(len(merge_df))\n",
    "merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df.Movie_runtime = merge_df.Movie_runtime.apply(lambda x:int(x) if pd.notna(x) else -1)\n",
    "len(merge_df[merge_df.runtimeMinutes == merge_df.Movie_runtime])\n",
    "# All the matched films have the same runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we add the ratings to the corresponding films: we lose 5 films which did not have ratings, which is negligeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7351\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_movie_ID</th>\n",
       "      <th>Freebase_movie_ID</th>\n",
       "      <th>Movie_name</th>\n",
       "      <th>Movie_release_date</th>\n",
       "      <th>Movie_box_office_revenue</th>\n",
       "      <th>Movie_runtime</th>\n",
       "      <th>Movie_languages</th>\n",
       "      <th>Movie_countries</th>\n",
       "      <th>Movie_genres</th>\n",
       "      <th>IMDb_index</th>\n",
       "      <th>...</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>tconstIdentifier</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Thriller, Science Fiction, Horror, Adventure,...</td>\n",
       "      <td>218707</td>\n",
       "      <td>...</td>\n",
       "      <td>movie</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>98</td>\n",
       "      <td>Action,Horror,Sci-Fi</td>\n",
       "      <td>tt0228333</td>\n",
       "      <td>4.9</td>\n",
       "      <td>55237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10408933</td>\n",
       "      <td>/m/02qc0j7</td>\n",
       "      <td>Alexander's Ragtime Band</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>106</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Musical, Comedy, Black-and-white]</td>\n",
       "      <td>29325</td>\n",
       "      <td>...</td>\n",
       "      <td>movie</td>\n",
       "      <td>Alexander's Ragtime Band</td>\n",
       "      <td>Alexander's Ragtime Band</td>\n",
       "      <td>0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>106</td>\n",
       "      <td>Drama,Music,Musical</td>\n",
       "      <td>tt0029852</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171005</td>\n",
       "      <td>/m/016ywb</td>\n",
       "      <td>Henry V</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>10161099.0</td>\n",
       "      <td>137</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>[Costume drama, War film, Epic, Period piece, ...</td>\n",
       "      <td>95308</td>\n",
       "      <td>...</td>\n",
       "      <td>movie</td>\n",
       "      <td>Henry V</td>\n",
       "      <td>Henry V</td>\n",
       "      <td>0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>137</td>\n",
       "      <td>Biography,Drama,History</td>\n",
       "      <td>tt0097499</td>\n",
       "      <td>7.5</td>\n",
       "      <td>30168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77856</td>\n",
       "      <td>/m/0kcn7</td>\n",
       "      <td>Mary Poppins</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>102272727.0</td>\n",
       "      <td>139</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Children's/Family, Musical, Fantasy, Comedy, ...</td>\n",
       "      <td>57208</td>\n",
       "      <td>...</td>\n",
       "      <td>movie</td>\n",
       "      <td>Mary Poppins</td>\n",
       "      <td>Mary Poppins</td>\n",
       "      <td>0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>139</td>\n",
       "      <td>Comedy,Family,Fantasy</td>\n",
       "      <td>tt0058331</td>\n",
       "      <td>7.8</td>\n",
       "      <td>173216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156558</td>\n",
       "      <td>/m/014k4y</td>\n",
       "      <td>Baby Boy</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>29381649.0</td>\n",
       "      <td>123</td>\n",
       "      <td>[English Language]</td>\n",
       "      <td>[United States of America]</td>\n",
       "      <td>[Crime Fiction, Drama, Coming of age]</td>\n",
       "      <td>244954</td>\n",
       "      <td>...</td>\n",
       "      <td>movie</td>\n",
       "      <td>Baby Boy</td>\n",
       "      <td>Baby Boy</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>130</td>\n",
       "      <td>Crime,Drama,Romance</td>\n",
       "      <td>tt0255819</td>\n",
       "      <td>6.4</td>\n",
       "      <td>14988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wikipedia_movie_ID Freebase_movie_ID                Movie_name  \\\n",
       "0              975900         /m/03vyhn            Ghosts of Mars   \n",
       "1            10408933        /m/02qc0j7  Alexander's Ragtime Band   \n",
       "2              171005         /m/016ywb                   Henry V   \n",
       "3               77856          /m/0kcn7              Mary Poppins   \n",
       "4              156558         /m/014k4y                  Baby Boy   \n",
       "\n",
       "   Movie_release_date  Movie_box_office_revenue  Movie_runtime  \\\n",
       "0              2001.0                14010832.0             98   \n",
       "1              1938.0                 3600000.0            106   \n",
       "2              1989.0                10161099.0            137   \n",
       "3              1964.0               102272727.0            139   \n",
       "4              2001.0                29381649.0            123   \n",
       "\n",
       "      Movie_languages             Movie_countries  \\\n",
       "0  [English Language]  [United States of America]   \n",
       "1  [English Language]  [United States of America]   \n",
       "2  [English Language]            [United Kingdom]   \n",
       "3  [English Language]  [United States of America]   \n",
       "4  [English Language]  [United States of America]   \n",
       "\n",
       "                                        Movie_genres  IMDb_index  ...  \\\n",
       "0  [Thriller, Science Fiction, Horror, Adventure,...      218707  ...   \n",
       "1                 [Musical, Comedy, Black-and-white]       29325  ...   \n",
       "2  [Costume drama, War film, Epic, Period piece, ...       95308  ...   \n",
       "3  [Children's/Family, Musical, Fantasy, Comedy, ...       57208  ...   \n",
       "4              [Crime Fiction, Drama, Coming of age]      244954  ...   \n",
       "\n",
       "  titleType              primaryTitle             originalTitle isAdult  \\\n",
       "0     movie            Ghosts of Mars            Ghosts of Mars       0   \n",
       "1     movie  Alexander's Ragtime Band  Alexander's Ragtime Band       0   \n",
       "2     movie                   Henry V                   Henry V       0   \n",
       "3     movie              Mary Poppins              Mary Poppins       0   \n",
       "4     movie                  Baby Boy                  Baby Boy       0   \n",
       "\n",
       "  startYear  runtimeMinutes                   genres tconstIdentifier  \\\n",
       "0    2001.0              98     Action,Horror,Sci-Fi        tt0228333   \n",
       "1    1938.0             106      Drama,Music,Musical        tt0029852   \n",
       "2    1989.0             137  Biography,Drama,History        tt0097499   \n",
       "3    1964.0             139    Comedy,Family,Fantasy        tt0058331   \n",
       "4    2001.0             130      Crime,Drama,Romance        tt0255819   \n",
       "\n",
       "  averageRating numVotes  \n",
       "0           4.9    55237  \n",
       "1           6.9     2159  \n",
       "2           7.5    30168  \n",
       "3           7.8   173216  \n",
       "4           6.4    14988  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df_ratings = pd.merge(merge_df, ratings_cleaned, left_on = 'tconst', right_on ='tconstIdentifier', how = \"inner\")\n",
    "print(len(merge_df_ratings))\n",
    "merge_df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['titleType', 'startYear', 'originalTitle'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [269], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Select the columns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmerge_df_ratings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitleType\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstartYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moriginalTitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Save the dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(DESTINATION \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerge_CMU_IMDb.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4957\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4809\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4811\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4818\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4819\u001b[0m ):\n\u001b[0;32m   4820\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4821\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4822\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4955\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4956\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4963\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4964\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4965\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6661\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6661\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6662\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['titleType', 'startYear', 'originalTitle'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Select the columns\n",
    "merge_df_ratings.drop(['titleType', 'startYear','originalTitle'], axis=1, inplace=True)\n",
    "\n",
    "# Save the dataset\n",
    "with open(DESTINATION + 'merge_CMU_IMDb.pkl', 'wb') as file:\n",
    "        pickle.dump(merge_df_ratings, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge this dataframe to the movie_stats one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'of', 'mars', 'ghosts'} 2001\n",
      "{'of', 'mars', 'ghosts'}\n",
      "ok\n",
      "{\"alexander's\", 'band', 'ragtime'} 1938\n",
      "{'v', 'henry'} 1989\n",
      "{'v', 'henry'}\n",
      "ok\n",
      "{'poppins', 'mary'} 1964\n",
      "{'boy', 'baby'} 2001\n",
      "{'boy', 'baby'}\n",
      "ok\n",
      "{'what', 'knew', 'wanted', 'they'} 1940\n",
      "{'be', 'the', 'must', 'crazy', 'gods'} 1980\n",
      "{'be', 'the', 'must', 'crazy', 'gods'}\n",
      "ok\n",
      "{'rudo', 'cursi', 'y'} 2008\n",
      "{'kinjite', 'subjects', 'forbidden'} 1989\n",
      "{'kinjite', 'subjects', 'forbidden'}\n",
      "ok\n",
      "{'loverboy'} 1989\n",
      "{'the', 'wagon', 'covered'} 1923\n",
      "{'the', 'hut', 'little'} 1957\n",
      "{'boston', 'the', 'strangler'} 1968\n",
      "{'die', 'dae-ro', \"can't\", 'lee'} 2005\n",
      "{'naked', 'the', 'kitchen'} 2009\n",
      "{'star!'} 1968\n",
      "{'great', 'the', 'santini'} 1979\n",
      "{'beachhead'} 1954\n",
      "{'to', 'when', 'do', 'in', 'denver', 'things', \"you're\", 'dead'} 1995\n",
      "{'to', 'when', 'do', 'in', 'denver', 'things', \"you're\", 'dead'}\n",
      "ok\n",
      "{'convoy'} 1978\n",
      "{'c.h.u.d.'} 1984\n",
      "{'c.h.u.d.'}\n",
      "ok\n",
      "{'cat', 'black', 'white'} 1998\n",
      "{'the', 'astronaut', 'farmer'} 2006\n",
      "{'the', 'astronaut', 'farmer'}\n",
      "ok\n",
      "{'dogs', 'straw'} 1971\n",
      "{'winter...', 'and', 'spring', 'fall', 'summer'} 2003\n",
      "{'blockade'} 1938\n",
      "{'grease'} 1978\n",
      "{'jane', 'becoming'} 2007\n",
      "{'jane', 'becoming'}\n",
      "ok\n",
      "{'express', 'midnight'} 1978\n",
      "{'robocop', '3'} 1993\n",
      "{'robocop', '3'}\n",
      "ok\n",
      "{'the', 'kingdom', 'forbidden'} 2008\n",
      "{'the', 'kingdom', 'forbidden'}\n",
      "ok\n",
      "{'superman'} 1978\n",
      "{'trial', 'and', 'error'} 1997\n",
      "{'roughness', 'necessary'} 1991\n",
      "{'roughness', 'necessary'}\n",
      "ok\n",
      "{'demon', 'of', 'barber', 'sweeney', 'todd', 'fleet', 'the', 'street'} 2007\n",
      "{'demon', 'of', 'barber', 'sweeney', 'todd', 'fleet', 'the', 'street'}\n",
      "ok\n",
      "{'chaplin'} 1992\n",
      "{'chaplin'}\n",
      "ok\n",
      "{'nothing', 'to', 'lose'} 1997\n",
      "{'nothing', 'to', 'lose'}\n",
      "ok\n",
      "{'13th', 'friday', 'chapter', 'the', 'final'} 1984\n",
      "{'13th', 'friday', 'chapter', 'the', 'final'}\n",
      "ok\n",
      "{'you', \"i'm\", 'losing'} 1998\n",
      "{'beastmaster', '2', 'of', 'through', 'time', 'the', 'portal'} 1991\n",
      "{'beastmaster', '2', 'of', 'through', 'time', 'the', 'portal'}\n",
      "ok\n",
      "{'rainbow', 'the', 'over'} 2002\n",
      "{'resident', 'evil'} 2002\n",
      "{'resident', 'evil'}\n",
      "ok\n",
      "{'nell'} 1994\n",
      "{'nell'}\n",
      "ok\n",
      "{'business', 'monkey'} 1952\n",
      "{'to', 'someone', 'me', 'watch', 'over'} 1987\n",
      "{'to', 'someone', 'me', 'watch', 'over'}\n",
      "ok\n",
      "{'your', 'could', 'woman', 'never', 'be', 'i'} 2007\n",
      "{'cyrano', 'agency'} 2010\n",
      "{'of', 'my', 'grace', 'heart'} 1996\n",
      "{'of', 'my', 'grace', 'heart'}\n",
      "ok\n",
      "{'just', 'wright'} 2010\n",
      "{'the', 'child', 'bless'} 2000\n",
      "{'the', 'child', 'bless'}\n",
      "ok\n",
      "{'the', 'program'} 1993\n",
      "{'the', 'program'}\n",
      "ok\n",
      "{'francisco', 'san'} 1936\n",
      "{'comebacks', 'the'} 2007\n",
      "{'comebacks', 'the'}\n",
      "ok\n",
      "{'brides'} 2004\n",
      "{'beauty', 'stage'} 2004\n",
      "{'in', 'jefferson', 'paris'} 1995\n",
      "{'in', 'jefferson', 'paris'}\n",
      "ok\n",
      "{'iron', 'the', 'lady'} 2011\n",
      "{'iron', 'the', 'lady'}\n",
      "ok\n",
      "{'next'} 2007\n",
      "{'next'}\n",
      "ok\n",
      "{'fish', 'go'} 1994\n",
      "{'contract', 'the'} 2006\n",
      "{'of', 'clash', 'the', 'titans'} 2010\n",
      "{'of', 'clash', 'the', 'titans'}\n",
      "ok\n",
      "{'g.i.', 'jane'} 1997\n",
      "{'g.i.', 'jane'}\n",
      "ok\n",
      "{'moment', 'a', 'dull', 'never'} 1950\n",
      "{'falling', 'snow', 'on', 'cedars'} 1999\n",
      "{'falling', 'snow', 'on', 'cedars'}\n",
      "ok\n",
      "{'chitty', 'bang'} 1968\n",
      "{'the', 'wyoming', 'from', 'redhead'} 1953\n",
      "{'diary', '26', 'years'} 2007\n",
      "{'godsend'} 2004\n",
      "{'track', '29'} 1988\n",
      "{'track', '29'}\n",
      "ok\n",
      "{'season', '3', 'open'} 2010\n",
      "{'the', \"don't\", 'rock', 'knock'} 1956\n",
      "{'and', 'created', 'woman', 'god'} 1988\n",
      "{'home', 'at', 'lives', 'jeff', 'who'} 2011\n",
      "{'days', 'palmy'} 1931\n",
      "{'single', 'a', 'man'} 2009\n",
      "{'single', 'a', 'man'}\n",
      "ok\n",
      "{'bangkok', 'dangerous'} 2008\n",
      "{'bangkok', 'dangerous'}\n",
      "ok\n",
      "{'cinderella'} 1950\n",
      "{'last', 'song', 'the'} 2010\n",
      "{'last', 'song', 'the'}\n",
      "ok\n",
      "{'petersen'} 1974\n",
      "{'my', 'fair', 'lady'} 1964\n",
      "{'house', 'of', 'yes', 'the'} 1997\n",
      "{'house', 'of', 'yes', 'the'}\n",
      "ok\n",
      "{'the', 'sure', 'thing'} 1985\n",
      "{'the', 'sure', 'thing'}\n",
      "ok\n",
      "{\"t'aime\", 'paris', 'je'} 2006\n",
      "{\"t'aime\", 'paris', 'je'}\n",
      "ok\n",
      "{'big', 'bad', 'mama'} 1974\n",
      "{'overheard', '2'} 2011\n",
      "{'is', 'cool', 'life'} 2008\n",
      "{'house', 'of', 'cards'} 1993\n",
      "{'looper'} 2012\n",
      "{'looper'}\n",
      "ok\n",
      "{'stroker', 'ace'} 1983\n",
      "{'crossover'} 2006\n",
      "{'for', 'game', 'of', 'love', 'the'} 1999\n",
      "{'for', 'game', 'of', 'love', 'the'}\n",
      "ok\n",
      "{'halloween', 'resurrection'} 2002\n",
      "{'halloween', 'resurrection'}\n",
      "ok\n",
      "{'way', 'to', 'the', 'gold'} 1957\n",
      "{'the', 'badlanders'} 1958\n",
      "{'beast', 'of', 'the', 'city'} 1932\n",
      "{'three', 'violent', 'people'} 1956\n",
      "{'empire', 'inland'} 2006\n",
      "{'of', 'the', 'rancho', 'rose'} 1914\n",
      "{'to', 'smoochy', 'death'} 2002\n",
      "{'to', 'smoochy', 'death'}\n",
      "ok\n",
      "{'fixed', 'bayonets!'} 1951\n",
      "{'are', 'chances'} 1989\n",
      "{'are', 'chances'}\n",
      "ok\n",
      "{'soldier', 'the', 'universal', 'return'} 1999\n",
      "{'soldier', 'the', 'universal', 'return'}\n",
      "ok\n",
      "{'3', 'strikes'} 2000\n",
      "{'brain', 'donors'} 1992\n",
      "{'banzai', 'of', 'across', 'the', '8th', 'dimension', 'buckaroo', 'adventures'} 1984\n",
      "{'of', 'dylan', 'night', 'dog', 'dead'} 2010\n",
      "{'welcome', 'to', 'mooseport'} 2004\n",
      "{'welcome', 'to', 'mooseport'}\n",
      "ok\n",
      "{'versa', 'vice'} 1988\n",
      "{'fields', 'the', 'killing'} 1984\n",
      "{'fields', 'the', 'killing'}\n",
      "ok\n",
      "{'foys', 'the', 'seven', 'little'} 1955\n",
      "{'inkheart'} 2008\n",
      "{'inkheart'}\n",
      "ok\n",
      "{'fire', 'with'} 1986\n",
      "{'tortilla', 'soup'} 2001\n",
      "{'house', 'party', '3'} 1994\n",
      "{'collector', 'the', 'bone'} 1999\n",
      "{'collector', 'the', 'bone'}\n",
      "ok\n",
      "{'house', 'party', '2'} 1991\n",
      "{'house', 'party', '2'}\n",
      "ok\n",
      "{'bambi'} 1942\n",
      "{'man', 'trouble'} 1992\n",
      "{'man', 'trouble'}\n",
      "ok\n",
      "{'at', 'tension', 'table', 'rock'} 1956\n",
      "{'and', 'king', 'richard', 'the', 'crusaders'} 1954\n",
      "{'smart', 'get'} 2008\n",
      "{'smart', 'get'}\n",
      "ok\n",
      "{'foreign', 'correspondent'} 1940\n",
      "{'of', 'pieces', 'april'} 2003\n",
      "{'of', 'pieces', 'april'}\n",
      "ok\n",
      "{'down', 'to', 'earth'} 2001\n",
      "{'down', 'to', 'earth'}\n",
      "ok\n",
      "{'serenity'} 2005\n",
      "{'serenity'}\n",
      "ok\n",
      "{'fatal', 'attraction'} 1987\n",
      "{'fatal', 'attraction'}\n",
      "ok\n",
      "{'throttle', 'full', 'angels', \"charlie's\"} 2003\n",
      "{'throttle', 'full', 'angels', \"charlie's\"}\n",
      "ok\n",
      "{'rocket', 'science'} 2007\n",
      "{'murdered', 'paradise'} 2007\n",
      "{'of', 'damned', 'the', 'queen'} 2002\n",
      "{'of', 'damned', 'the', 'queen'}\n",
      "ok\n",
      "{'prodigal', 'the'} 1955\n",
      "{'in', '3', 'back', 'police', 'training', 'academy'} 1986\n",
      "{'hello', 'dolly!'} 1969\n",
      "{'gray', 'in', 'suit', 'the', 'man', 'flannel'} 1956\n",
      "{'34th', 'miracle', 'on', 'street'} 1994\n",
      "{'off', 'a', 'place', 'far'} 1993\n",
      "{'in', 'the', 'dark', 'man'} 1953\n",
      "{'broken', 'not', 'easily'} 2009\n",
      "{'boiling', 'point'} 1993\n",
      "{'boiling', 'point'}\n",
      "ok\n",
      "{'unmarried', 'an', 'woman'} 1978\n",
      "{'of', 'paleface', 'son'} 1952\n",
      "{'drop', 'zone'} 1994\n",
      "{'drop', 'zone'}\n",
      "ok\n",
      "{'halloween', 'of', '4', 'michael', 'the', 'myers', 'return'} 1988\n",
      "{'halloween', 'of', '4', 'michael', 'the', 'myers', 'return'}\n",
      "ok\n",
      "{'saturn', '3'} 1980\n",
      "{'3-iron'} 2004\n",
      "{'3-iron'}\n",
      "ok\n",
      "{'wetherby'} 1985\n",
      "{'juice'} 1992\n",
      "{'juice'}\n",
      "ok\n",
      "{'pass', 'hall'} 2011\n",
      "{'pass', 'hall'}\n",
      "ok\n",
      "{'la', 'monaco', 'fille', 'de'} 2008\n",
      "{'gymkata'} 1985\n",
      "{'no', 'of', 'son', 'one', 'the'} 2011\n",
      "{'troll'} 1986\n",
      "{'troll'}\n",
      "ok\n",
      "{'greatest', 'story', 'the', 'told', 'ever'} 1965\n",
      "{'scoundrels', 'for', 'school'} 2006\n",
      "{'duty', 'jury'} 1995\n",
      "{'blue', 'three', 'colors'} 1993\n",
      "{'major', 'league'} 1989\n",
      "{'major', 'league'}\n",
      "ok\n",
      "{'she-devil'} 1989\n",
      "{'just', 'luck', 'my'} 2006\n",
      "{'just', 'luck', 'my'}\n",
      "ok\n",
      "{'picture', 'last', 'the', 'show'} 1971\n",
      "{'a', 'man', 'reasonable'} 1999\n",
      "{'nowhere', 'camp'} 1994\n",
      "{'during', 'life', 'wartime'} 2009\n",
      "{'and', 'learned', 'to', 'worrying', 'or', 'strangelove', 'stop', 'dr.', 'love', 'bomb', 'the', 'how', 'i'} 1964\n",
      "{'gold', \"fool's\"} 2008\n",
      "{'gold', \"fool's\"}\n",
      "ok\n",
      "{'selena'} 1997\n",
      "{'selena'}\n",
      "ok\n",
      "{'puss', 'in', 'boots'} 2011\n",
      "{'puss', 'in', 'boots'}\n",
      "ok\n",
      "{'straight', 'the', 'story'} 1999\n",
      "{'straight', 'the', 'story'}\n",
      "ok\n",
      "{'rush', 'the', 'adrenalin', 'fear'} 1996\n",
      "{'quid', 'pro', 'quo'} 2008\n",
      "{'er', 'conde', 'jones'} 2011\n",
      "{'west', 'fievel', 'goes', 'an', 'american', 'tail'} 1991\n",
      "{'brides', 'of', 'the', 'battle'} 2011\n",
      "{'just', 'between', 'friends'} 1986\n",
      "{'lolita'} 1962\n",
      "{'at', 'meet', 'me', 'the', 'fair'} 1953\n",
      "{'of', 'musketeers', 'the', 'revenge'} 1994\n",
      "{'of', 'baby', 'lost', 'the', 'legend', 'secret'} 1985\n",
      "{'wolf', 'teen', 'too'} 1987\n",
      "{'wolf', 'teen', 'too'}\n",
      "ok\n",
      "{'shine'} 1996\n",
      "{'shine'}\n",
      "ok\n",
      "{'unzipped'} 1995\n",
      "{'the', 'widowmaker', 'k-19'} 2002\n",
      "{'the', 'widowmaker', 'k-19'}\n",
      "ok\n",
      "{'shallow', 'hal'} 2001\n",
      "{'shallow', 'hal'}\n",
      "ok\n",
      "{'way', 'the', 'along', 'trouble'} 1953\n",
      "{'the', 'hunted'} 1995\n",
      "{'the', 'hunted'}\n",
      "ok\n",
      "{'home', 'yellow', 'of', 'from', 'the', 'far', 'dog', 'adventures'} 1995\n",
      "{'kaboom'} 2010\n",
      "{'robocop'} 1987\n",
      "{'robocop'}\n",
      "ok\n",
      "{'bee', 'season'} 2005\n",
      "{'mr.', 'emmanuel'} 1944\n",
      "{'max', 'schmeling'} 2010\n",
      "{'airplane!'} 1980\n",
      "{'airplane!'}\n",
      "ok\n",
      "{'attraction', 'bewitching'} 2006\n",
      "{'witches', 'the'} 1990\n",
      "{'the', 'groove', 'tube'} 1974\n",
      "{'gothic'} 1986\n",
      "{'because', 'said', 'so', 'i'} 2007\n",
      "{'water'} 2005\n",
      "{'pass', 'raton'} 1951\n",
      "{'sonja', 'red'} 1985\n",
      "{'sonja', 'red'}\n",
      "ok\n",
      "{'adventure', 'incredibly', 'of', 'in', 'love', 'the', 'girls', 'two', 'true'} 1995\n",
      "{'adventure', 'incredibly', 'of', 'in', 'love', 'the', 'girls', 'two', 'true'}\n",
      "ok\n",
      "{'and', 'a', 'noodle', 'woman', 'shop', 'gun'} 2009\n",
      "{'town', 'covers', 'francis', 'big', 'the'} 1953\n",
      "{'king', 'of', 'quarters', 'kong', 'a', 'fistful', 'the'} 2007\n",
      "{'medicine', 'man'} 1992\n",
      "{'medicine', 'man'}\n",
      "ok\n",
      "{'somewhere'} 2010\n",
      "{'somewhere'}\n",
      "ok\n",
      "{'baba', 'of', 'hajji', 'the', 'adventures'} 1954\n",
      "{'at', 'bad', 'black', 'rock', 'day'} 1955\n",
      "{\"prizzi's\", 'honor'} 1985\n",
      "{'fled'} 1996\n",
      "{'fled'}\n",
      "ok\n",
      "{'girl', 'the', 'other', 'boleyn'} 2008\n",
      "{'girl', 'the', 'other', 'boleyn'}\n",
      "ok\n",
      "{'fire', 'on', 'man'} 1987\n",
      "{'dirty', 'dancing'} 1987\n",
      "{'dirty', 'dancing'}\n",
      "ok\n",
      "{'4', 'scream'} 2011\n",
      "{'4', 'scream'}\n",
      "ok\n",
      "{\"donovan's\", 'young', 'kid'} 1931\n",
      "{'of', 'life', 'gale', 'the', 'david'} 2003\n",
      "{'of', 'life', 'gale', 'the', 'david'}\n",
      "ok\n",
      "{'iron', 'man', '2'} 2010\n",
      "{'iron', 'man', '2'}\n",
      "ok\n",
      "{'of', 'prince', 'foxes'} 1949\n",
      "{'set', 'desk'} 1957\n",
      "{'antichrist'} 2009\n",
      "{'antichrist'}\n",
      "ok\n",
      "{'pink', 'the', 'panther'} 1963\n",
      "{'rock!', 'shake', 'rattle', '&'} 1956\n",
      "{'stander'} 2003\n",
      "{'confidential', 'l.a.'} 1997\n",
      "{'confidential', 'l.a.'}\n",
      "ok\n",
      "{'my', 'the', 'father', 'hero'} 1994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'omen', 'the'} 1976\n",
      "{'horizons', 'the', 'far'} 1955\n",
      "{'giant'} 1956\n",
      "{'great', 'lover', 'the'} 1949\n",
      "{'before', 'mast', 'the', 'years', 'two'} 1946\n",
      "{'terri'} 2011\n",
      "{'30', 'going', 'on', '13'} 2004\n",
      "{'30', 'going', 'on', '13'}\n",
      "ok\n",
      "{'the', 'perfect', 'game'} 2009\n",
      "{'algiers'} 1938\n",
      "{'to', 'goes', 'ernest', 'camp'} 1987\n",
      "{'to', 'goes', 'ernest', 'camp'}\n",
      "ok\n",
      "{'your', 'only', 'for', 'eyes'} 1981\n",
      "{'your', 'only', 'for', 'eyes'}\n",
      "ok\n",
      "{'county', 'line', 'macon'} 1974\n",
      "{'birth', 'of', 'nation', 'a', 'the'} 1915\n",
      "{'six', 'days', 'seven', 'nights'} 1998\n",
      "{'six', 'days', 'seven', 'nights'}\n",
      "ok\n",
      "{'dreamz', 'american'} 2006\n",
      "{'king', 'of', 'kings'} 1961\n",
      "{'colombiana'} 2011\n",
      "{'colombiana'}\n",
      "ok\n",
      "{'of', 'the', 'year', 'comet'} 1992\n",
      "{'connection', 'french', 'ii'} 1975\n",
      "{'next', 'friday', 'after'} 2002\n",
      "{'next', 'friday', 'after'}\n",
      "ok\n",
      "{'prejudice', 'extreme'} 1987\n",
      "{'prejudice', 'extreme'}\n",
      "ok\n",
      "{'parts', 'speaking'} 1989\n",
      "{'sky', 'high'} 2005\n",
      "{'sky', 'high'}\n",
      "ok\n",
      "{'of', 'dreams', 'winter', 'our'} 1981\n",
      "{\"henry's\", 'crime'} 2010\n",
      "{\"henry's\", 'crime'}\n",
      "ok\n",
      "{'in', 'sleepless', 'seattle'} 1993\n",
      "{'in', 'sleepless', 'seattle'}\n",
      "ok\n",
      "{'first', 'the', 'texan'} 1956\n",
      "{'movie', 'road'} 2002\n",
      "{'and', '2', 'months', '4', 'days', 'weeks', '3'} 2007\n",
      "{'starting', 'in', 'evening', 'the', 'out'} 2007\n",
      "{'newsies'} 1992\n",
      "{'newsies'}\n",
      "ok\n",
      "{'that', 'do!', 'you', 'thing'} 1996\n",
      "{'that', 'do!', 'you', 'thing'}\n",
      "ok\n",
      "{'days', 'seven'} 2007\n",
      "{'the', 'white', 'countess'} 2005\n",
      "{'last', 'summer', 'suddenly'} 1959\n",
      "{\"monster's\", 'ball'} 2001\n",
      "{\"monster's\", 'ball'}\n",
      "ok\n",
      "{'with', 'scot', 'breakfast'} 2007\n",
      "{'in', 'battle', 'seattle'} 2007\n",
      "{'ambush'} 1950\n",
      "{\"boyfriend's\", 'back', 'my'} 1993\n",
      "{\"boyfriend's\", 'back', 'my'}\n",
      "ok\n",
      "{'of', 'brave', 'the', 'home'} 1949\n",
      "{'pride', 'celtic'} 1996\n",
      "{'hard', 'spy'} 1996\n",
      "{'hard', 'spy'}\n",
      "ok\n",
      "{'volcano'} 1997\n",
      "{'volcano'}\n",
      "ok\n",
      "{'toys'} 1992\n",
      "{'toys'}\n",
      "ok\n",
      "{'fastest', 'the', 'indian', \"world's\"} 2005\n",
      "{'fastest', 'the', 'indian', \"world's\"}\n",
      "ok\n",
      "{'bodyguards', 'and', 'assassins'} 2009\n",
      "{'knows', \"you're\", 'alone', 'he'} 1980\n",
      "{'you', 'just', 'want', 'me', 'tell', 'what'} 1980\n",
      "{'heartbreakers'} 2001\n",
      "{'heartbreakers'}\n",
      "ok\n",
      "{'spider-man'} 2002\n",
      "{'spider-man'}\n",
      "ok\n",
      "{'sin', 'original'} 2001\n",
      "{'sin', 'original'}\n",
      "ok\n",
      "{'cirque', 'assistant', \"vampire's\", 'the', 'freak', 'du'} 2009\n",
      "{'cirque', 'assistant', \"vampire's\", 'the', 'freak', 'du'}\n",
      "ok\n",
      "{'of', 'the', 'return', 'dead', 'living'} 1985\n",
      "{'of', 'the', 'return', 'dead', 'living'}\n",
      "ok\n",
      "{'dungeons', '&', 'dragons'} 2000\n",
      "{'dungeons', '&', 'dragons'}\n",
      "ok\n",
      "{'the', 'scout'} 1994\n",
      "{'ginger', 'snaps', 'unleashed', '2'} 2004\n",
      "{'caramel'} 2007\n",
      "{'the', 'quiet', 'man'} 1952\n",
      "{'violent', 'the', 'men'} 1955\n",
      "{'for', 'grounds', 'marriage'} 1951\n",
      "{'lone', 'mcquade', 'wolf'} 1983\n",
      "{'lone', 'mcquade', 'wolf'}\n",
      "ok\n",
      "{'harry', 'brown'} 2009\n",
      "{'harry', 'brown'}\n",
      "ok\n",
      "{'the', 'man', 'leading'} 1996\n",
      "{'anthem', 'american'} 1986\n",
      "{'have', 'everything', 'yours', 'is', 'i'} 1952\n",
      "{'5', 'destination', 'final'} 2011\n",
      "{'5', 'destination', 'final'}\n",
      "ok\n",
      "{'a', 'little', 'princess'} 1995\n",
      "{'a', 'little', 'princess'}\n",
      "ok\n",
      "{'welcome', 'to', 'collinwood'} 2002\n",
      "{'tarzan'} 1999\n",
      "{'tarzan'}\n",
      "ok\n",
      "{'we', 'zoo', 'bought', 'a'} 2011\n",
      "{'we', 'zoo', 'bought', 'a'}\n",
      "ok\n",
      "{'bears', 'the', 'country'} 2002\n",
      "{'bears', 'the', 'country'}\n",
      "ok\n",
      "{'mommas', 'big', 'father', 'son', 'like'} 2011\n",
      "{'mommas', 'big', 'father', 'son', 'like'}\n",
      "ok\n",
      "{'was', 'he', 'a', 'quiet', 'man'} 2007\n",
      "{'of', 'tenants', 'prosperity', '72'} 2010\n",
      "{'and', 'now', 'then'} 1995\n",
      "{'a', 'million'} 2009\n",
      "{'in', 'hole', 'the', 'ace'} 1951\n",
      "{'the', 'spain', 'kid', 'from'} 1932\n",
      "{'girl', 'the', 'dead'} 2006\n",
      "{'worth', 'fort'} 1951\n",
      "{'hat', 'top'} 1935\n",
      "{'bones'} 2001\n",
      "{'bones'}\n",
      "ok\n",
      "{'diggers'} 2006\n",
      "{'born', 'is', 'a', 'star'} 1976\n",
      "{'the', 'on', 'woman', 'beach'} 2006\n",
      "{'secret', 'the', 'garden'} 1993\n",
      "{'secret', 'the', 'garden'}\n",
      "ok\n",
      "{'a', 'christmas', 'tale'} 2008\n",
      "{'ted', 'bundy'} 2002\n",
      "{'ted', 'bundy'}\n",
      "ok\n",
      "{'squad', 'vice'} 1982\n",
      "{'movie', 'scary', '2'} 2001\n",
      "{'movie', 'scary', '2'}\n",
      "ok\n",
      "{'burnt', 'sun', 'by', '2', 'the'} 2010\n",
      "{'10', 'to', '3', 'yuma'} 1957\n",
      "{'battlefield', 'earth'} 2000\n",
      "{'battlefield', 'earth'}\n",
      "ok\n",
      "{'of', 'the', 'dark', 'out'} 1988\n",
      "{'in', 'night', 'vigil', 'the'} 1940\n",
      "{'no', 'nanette'} 1940\n",
      "{'semum'} 2008\n",
      "{'carroll', 'house', 'the', 'street', 'on'} 1988\n",
      "{'cars'} 2006\n",
      "{'cars'}\n",
      "ok\n",
      "{'the', 'daughter', \"general's\"} 1999\n",
      "{'the', 'daughter', \"general's\"}\n",
      "ok\n",
      "{'boy', \"mama's\"} 2007\n",
      "{'jonah', 'hex'} 2010\n",
      "{'jonah', 'hex'}\n",
      "ok\n",
      "{'christina', 'queen'} 1933\n",
      "{'and', 'the', 'birds', 'bees'} 1956\n",
      "{'sister', 'the', 'other'} 1999\n",
      "{'sister', 'the', 'other'}\n",
      "ok\n",
      "{'condition', 'heart'} 1990\n",
      "{'of', 'day', 'light'} 1987\n",
      "{'a', \"it's\", 'wonderful', 'life'} 1946\n",
      "{'timothy', 'of', 'life', 'the', 'odd', 'green'} 2012\n",
      "{'timothy', 'of', 'life', 'the', 'odd', 'green'}\n",
      "ok\n",
      "{'the', 'racers'} 1955\n",
      "{'ransom!'} 1956\n",
      "{'victim', 'the'} 1980\n",
      "{'macao'} 1952\n",
      "{'halls', 'the', 'deck'} 2006\n",
      "{'of', 'lies', 'body'} 2008\n",
      "{'of', 'lies', 'body'}\n",
      "ok\n",
      "{'sabrina'} 1995\n",
      "{'sabrina'}\n",
      "ok\n",
      "{'hoot'} 2006\n",
      "{'hoot'}\n",
      "ok\n",
      "{'food', 'soul'} 1997\n",
      "{'food', 'soul'}\n",
      "ok\n",
      "{'no', 'for', 'men', 'old', 'country'} 2007\n",
      "{'no', 'for', 'men', 'old', 'country'}\n",
      "ok\n",
      "{'the', 'bear'} 1988\n",
      "{'8mm'} 1999\n",
      "{'8mm'}\n",
      "ok\n",
      "{\"i'll\", 'anything', 'do'} 1994\n",
      "{'octopussy'} 1983\n",
      "{'octopussy'}\n",
      "ok\n",
      "{'of', 'king', 'last', 'the', 'scotland'} 2006\n",
      "{'of', 'king', 'last', 'the', 'scotland'}\n",
      "ok\n",
      "{'trixie'} 2000\n",
      "{'the', 'bloom', 'brothers'} 2008\n",
      "{'the', 'bloom', 'brothers'}\n",
      "ok\n",
      "{'yourself!', 'behave'} 1951\n",
      "{'rescuers', 'the'} 1977\n",
      "{'states', 'altered'} 1980\n",
      "{'rv'} 2006\n",
      "{'rv'}\n",
      "ok\n",
      "{'wives', 'the', 'stepford'} 2004\n",
      "{'wives', 'the', 'stepford'}\n",
      "ok\n",
      "{'panic'} 2000\n",
      "{'fate'} 2008\n",
      "{'tadpole'} 2002\n",
      "{\"jupiter's\", 'darling'} 1955\n",
      "{'wish', 'death'} 1974\n",
      "{'awakenings'} 1990\n",
      "{'awakenings'}\n",
      "ok\n",
      "{'talk', 'to', 'about', 'something'} 1995\n",
      "{'screwed'} 2000\n",
      "{'caligula'} 1979\n",
      "{'pretty', 'dirty', 'things'} 2002\n",
      "{'pretty', 'dirty', 'things'}\n",
      "ok\n",
      "{'critical', 'condition'} 1987\n",
      "{'critical', 'condition'}\n",
      "ok\n",
      "{'happy', 'texas'} 1999\n",
      "{'happy', 'texas'}\n",
      "ok\n",
      "{'sugar', 'spice', '&'} 2001\n",
      "{'sugar', 'spice', '&'}\n",
      "ok\n",
      "{'munich'} 2005\n",
      "{'munich'}\n",
      "ok\n",
      "{'ii', 'dundee', 'crocodile'} 1988\n",
      "{'ii', 'dundee', 'crocodile'}\n",
      "ok\n",
      "{'in', 'the', 'crowd'} 1988\n",
      "{'dillinger'} 1973\n",
      "{'girl', 'dragon', 'with', 'the', 'tattoo'} 2009\n",
      "{'girl', 'dragon', 'with', 'the', 'tattoo'}\n",
      "ok\n",
      "{'searchers', 'the'} 1956\n",
      "{'of', 'wizard', 'the', 'oz'} 1939\n",
      "{'camp'} 2003\n",
      "{'carrington'} 1995\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [272], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m MERGE_AGAIN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m MERGE_AGAIN:\n\u001b[1;32m----> 3\u001b[0m     matched \u001b[38;5;241m=\u001b[39m \u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerge_df_ratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmovie_stats_cleaned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMovie_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMovie_release_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# save the matching table\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(DESTINATION\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatching_table_bis.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "Cell \u001b[1;32mIn [271], line 12\u001b[0m, in \u001b[0;36mcompare\u001b[1;34m(df1, df2, col1_title, col2_title, col1_year, col2_year, threshold, delta_year)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(title1,y1)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#for idx2,row2 in df2[df2[col2_year].isin([y1-delta_year+i for i in range(delta_year*2)])].iterrows():\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx2,row2 \u001b[38;5;129;01min\u001b[39;00m df2[\u001b[43mdf2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol2_year\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43my1\u001b[49m]\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     13\u001b[0m     title2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(re\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[ :,]\u001b[39m\u001b[38;5;124m'\u001b[39m,row2[col2_title]\u001b[38;5;241m.\u001b[39mlower()))\n\u001b[0;32m     14\u001b[0m     title2 \u001b[38;5;241m=\u001b[39m title2\u001b[38;5;241m.\u001b[39mdifference(punctuation)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:5623\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5620\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 5623\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:286\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 286\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:163\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    160\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:128\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    125\u001b[0m     _store_test_result(result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_evaluate_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:69\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     68\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " if MERGE_AGAIN:\n",
    "    matched = compare(merge_df_ratings,movie_stats_cleaned, 'Movie_name', 'name', 'Movie_release_date', 'year')\n",
    "    # save the matching table\n",
    "    with open(DESTINATION+'matching_table_bis.pkl', 'wb') as file:\n",
    "        pickle.dump(matched, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    matched = pd.read_pickle(DESTINATION+'matching_table_bis.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3514\n",
      "5497\n",
      "7351\n"
     ]
    }
   ],
   "source": [
    "print(len(matched))\n",
    "print(len(movie_stats_cleaned))\n",
    "print(len(merge_df_ratings))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
